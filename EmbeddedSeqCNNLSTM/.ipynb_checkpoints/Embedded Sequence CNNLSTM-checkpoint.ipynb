{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMy Attempt at the Raw Sequence Embedding CNN-LSTM at:\\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC5747425/pdf/pone.0188129.pdf\\nWorks by embedding sequence as a vector prior to 2-layer CNN and LSTM\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "My Attempt at the Raw Sequence Embedding CNN-LSTM at:\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5747425/pdf/pone.0188129.pdf\n",
    "Works by embedding sequence as a vector prior to 2-layer CNN and LSTM\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, AveragePooling2D, Dense, Dropout, Activation, AveragePooling1D, Reshape, Bidirectional, GlobalMaxPooling1D\n",
    "from keras.layers import Input, Concatenate, Flatten, Embedding, CuDNNLSTM, Conv1D, MaxPooling1D, LSTM, TimeDistributed, MaxPooling2D, GaussianNoise, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 672)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 672, 16)           80        \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 672, 64)           16448     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 84, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 84, 512)           659456    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 43008)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              44041216  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 44,718,225\n",
      "Trainable params: 44,718,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69023, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-01-0.69.hdf5\n",
      " - 54s - loss: 0.6918 - binary_accuracy: 0.5187 - val_loss: 0.6902 - val_binary_accuracy: 0.5137\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69023 to 0.68553, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-02-0.69.hdf5\n",
      " - 50s - loss: 0.6888 - binary_accuracy: 0.5400 - val_loss: 0.6855 - val_binary_accuracy: 0.5417\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.68553 to 0.67631, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-03-0.68.hdf5\n",
      " - 50s - loss: 0.6827 - binary_accuracy: 0.5560 - val_loss: 0.6763 - val_binary_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.67631 to 0.65542, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-04-0.66.hdf5\n",
      " - 50s - loss: 0.6704 - binary_accuracy: 0.5939 - val_loss: 0.6554 - val_binary_accuracy: 0.6511\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.65542 to 0.62867, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-05-0.63.hdf5\n",
      " - 50s - loss: 0.6330 - binary_accuracy: 0.6509 - val_loss: 0.6287 - val_binary_accuracy: 0.6430\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.62867 to 0.59769, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-06-0.60.hdf5\n",
      " - 51s - loss: 0.5959 - binary_accuracy: 0.6805 - val_loss: 0.5977 - val_binary_accuracy: 0.6704\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.59769 to 0.58783, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-07-0.59.hdf5\n",
      " - 50s - loss: 0.5765 - binary_accuracy: 0.6927 - val_loss: 0.5878 - val_binary_accuracy: 0.6677\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.58783 to 0.56691, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-08-0.57.hdf5\n",
      " - 50s - loss: 0.5639 - binary_accuracy: 0.7040 - val_loss: 0.5669 - val_binary_accuracy: 0.7006\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 46s - loss: 0.5573 - binary_accuracy: 0.7098 - val_loss: 0.5880 - val_binary_accuracy: 0.6683\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.56691 to 0.56174, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-10-0.56.hdf5\n",
      " - 51s - loss: 0.5498 - binary_accuracy: 0.7130 - val_loss: 0.5617 - val_binary_accuracy: 0.7049\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.56174 to 0.55351, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-11-0.55.hdf5\n",
      " - 51s - loss: 0.5458 - binary_accuracy: 0.7141 - val_loss: 0.5535 - val_binary_accuracy: 0.7092\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.55351 to 0.54810, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-12-0.55.hdf5\n",
      " - 51s - loss: 0.5387 - binary_accuracy: 0.7188 - val_loss: 0.5481 - val_binary_accuracy: 0.7065\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 47s - loss: 0.5357 - binary_accuracy: 0.7213 - val_loss: 0.5526 - val_binary_accuracy: 0.7151\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.54810 to 0.53878, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-14-0.54.hdf5\n",
      " - 51s - loss: 0.5299 - binary_accuracy: 0.7270 - val_loss: 0.5388 - val_binary_accuracy: 0.7184\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.53878 to 0.53768, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-15-0.54.hdf5\n",
      " - 52s - loss: 0.5255 - binary_accuracy: 0.7307 - val_loss: 0.5377 - val_binary_accuracy: 0.7291\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.53768 to 0.53097, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-16-0.53.hdf5\n",
      " - 51s - loss: 0.5221 - binary_accuracy: 0.7351 - val_loss: 0.5310 - val_binary_accuracy: 0.7302\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 46s - loss: 0.5173 - binary_accuracy: 0.7389 - val_loss: 0.5378 - val_binary_accuracy: 0.7108\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 46s - loss: 0.5146 - binary_accuracy: 0.7384 - val_loss: 0.5400 - val_binary_accuracy: 0.7076\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.53097 to 0.52953, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-19-0.53.hdf5\n",
      " - 51s - loss: 0.5137 - binary_accuracy: 0.7379 - val_loss: 0.5295 - val_binary_accuracy: 0.7243\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 46s - loss: 0.5099 - binary_accuracy: 0.7393 - val_loss: 0.5342 - val_binary_accuracy: 0.7237\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.52953 to 0.52822, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-21-0.53.hdf5\n",
      " - 50s - loss: 0.5094 - binary_accuracy: 0.7404 - val_loss: 0.5282 - val_binary_accuracy: 0.7259\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 46s - loss: 0.5064 - binary_accuracy: 0.7425 - val_loss: 0.5297 - val_binary_accuracy: 0.7270\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 46s - loss: 0.5055 - binary_accuracy: 0.7419 - val_loss: 0.5289 - val_binary_accuracy: 0.7232\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.52822 to 0.52311, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-24-0.52.hdf5\n",
      " - 51s - loss: 0.5019 - binary_accuracy: 0.7432 - val_loss: 0.5231 - val_binary_accuracy: 0.7227\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.52311 to 0.52015, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-25-0.52.hdf5\n",
      " - 50s - loss: 0.5021 - binary_accuracy: 0.7459 - val_loss: 0.5201 - val_binary_accuracy: 0.7324\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 46s - loss: 0.4977 - binary_accuracy: 0.7459 - val_loss: 0.5248 - val_binary_accuracy: 0.7351\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 46s - loss: 0.4989 - binary_accuracy: 0.7463 - val_loss: 0.5314 - val_binary_accuracy: 0.7237\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 46s - loss: 0.4958 - binary_accuracy: 0.7483 - val_loss: 0.5248 - val_binary_accuracy: 0.7275\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.52015 to 0.51833, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-29-0.52.hdf5\n",
      " - 51s - loss: 0.4947 - binary_accuracy: 0.7474 - val_loss: 0.5183 - val_binary_accuracy: 0.7302\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 46s - loss: 0.4917 - binary_accuracy: 0.7482 - val_loss: 0.5320 - val_binary_accuracy: 0.7254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27997082f60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic 1D Conv CNN LSTM\n",
    "\n",
    "start_target_size = (672)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/y_train.npy')\n",
    "\n",
    "\n",
    "# model\n",
    "inputs = Input(shape=[start_target_size])\n",
    "x = Embedding(input_dim = 5, output_dim=16, mask_zero=False, input_length=start_target_size)(inputs)\n",
    "x = Conv1D(64, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x = MaxPooling1D(pool_size=8, strides=8)(x)\n",
    "x = Bidirectional(CuDNNLSTM(256, return_sequences=True))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs = predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=0.001, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "root_path = 'D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights'\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(root_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=1, \n",
    "                                             save_best_only=True,\n",
    "                                             save_weights_only=False,\n",
    "                                             mode='auto',\n",
    "                                             period=1)\n",
    "\n",
    "csv_path = os.path.join(root_path, 'training_history.csv')\n",
    "csv_logger = CSVLogger(csv_path, separator=',', append=False)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 672)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 672, 16)      80          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 672, 64)      16448       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 672, 64)      65600       conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 672, 128)     0           conv1d_6[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 168, 128)     0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 168, 256)     264192      max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 43008)        0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1024)         44041216    flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            1025        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,388,561\n",
      "Trainable params: 44,388,561\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68405, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-01-0.68.hdf5\n",
      " - 61s - loss: 0.6895 - binary_accuracy: 0.5394 - val_loss: 0.6841 - val_binary_accuracy: 0.5401\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68405 to 0.66734, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-02-0.67.hdf5\n",
      " - 59s - loss: 0.6780 - binary_accuracy: 0.5728 - val_loss: 0.6673 - val_binary_accuracy: 0.6333\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.66734 to 0.61846, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-03-0.62.hdf5\n",
      " - 59s - loss: 0.6426 - binary_accuracy: 0.6389 - val_loss: 0.6185 - val_binary_accuracy: 0.6704\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61846 to 0.58227, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-04-0.58.hdf5\n",
      " - 59s - loss: 0.5966 - binary_accuracy: 0.6755 - val_loss: 0.5823 - val_binary_accuracy: 0.6941\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.58227 to 0.57390, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-05-0.57.hdf5\n",
      " - 59s - loss: 0.5732 - binary_accuracy: 0.6947 - val_loss: 0.5739 - val_binary_accuracy: 0.6769\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.57390 to 0.56051, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-06-0.56.hdf5\n",
      " - 60s - loss: 0.5605 - binary_accuracy: 0.7035 - val_loss: 0.5605 - val_binary_accuracy: 0.7081\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 55s - loss: 0.5524 - binary_accuracy: 0.7136 - val_loss: 0.5624 - val_binary_accuracy: 0.7124\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56051 to 0.55429, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-08-0.55.hdf5\n",
      " - 60s - loss: 0.5438 - binary_accuracy: 0.7175 - val_loss: 0.5543 - val_binary_accuracy: 0.7108\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.55429 to 0.54857, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-09-0.55.hdf5\n",
      " - 60s - loss: 0.5381 - binary_accuracy: 0.7220 - val_loss: 0.5486 - val_binary_accuracy: 0.7130\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.54857 to 0.54113, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-10-0.54.hdf5\n",
      " - 59s - loss: 0.5307 - binary_accuracy: 0.7295 - val_loss: 0.5411 - val_binary_accuracy: 0.7221\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.54113 to 0.53899, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-11-0.54.hdf5\n",
      " - 59s - loss: 0.5259 - binary_accuracy: 0.7320 - val_loss: 0.5390 - val_binary_accuracy: 0.7216\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.53899 to 0.53306, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-12-0.53.hdf5\n",
      " - 60s - loss: 0.5198 - binary_accuracy: 0.7343 - val_loss: 0.5331 - val_binary_accuracy: 0.7243\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 55s - loss: 0.5153 - binary_accuracy: 0.7375 - val_loss: 0.5352 - val_binary_accuracy: 0.7243\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.53306 to 0.52382, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-14-0.52.hdf5\n",
      " - 60s - loss: 0.5111 - binary_accuracy: 0.7413 - val_loss: 0.5238 - val_binary_accuracy: 0.7307\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 55s - loss: 0.5069 - binary_accuracy: 0.7420 - val_loss: 0.5304 - val_binary_accuracy: 0.7313\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 55s - loss: 0.5058 - binary_accuracy: 0.7429 - val_loss: 0.5254 - val_binary_accuracy: 0.7124\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 55s - loss: 0.5015 - binary_accuracy: 0.7419 - val_loss: 0.5301 - val_binary_accuracy: 0.7254\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 55s - loss: 0.4966 - binary_accuracy: 0.7465 - val_loss: 0.5250 - val_binary_accuracy: 0.7184\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.52382 to 0.51771, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-19-0.52.hdf5\n",
      " - 59s - loss: 0.4959 - binary_accuracy: 0.7460 - val_loss: 0.5177 - val_binary_accuracy: 0.7313\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 55s - loss: 0.4934 - binary_accuracy: 0.7486 - val_loss: 0.5197 - val_binary_accuracy: 0.7281\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 55s - loss: 0.4891 - binary_accuracy: 0.7494 - val_loss: 0.5208 - val_binary_accuracy: 0.7286\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 55s - loss: 0.4867 - binary_accuracy: 0.7504 - val_loss: 0.5190 - val_binary_accuracy: 0.7307\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.51771 to 0.51394, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-23-0.51.hdf5\n",
      " - 59s - loss: 0.4847 - binary_accuracy: 0.7523 - val_loss: 0.5139 - val_binary_accuracy: 0.7307\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 55s - loss: 0.4830 - binary_accuracy: 0.7543 - val_loss: 0.5150 - val_binary_accuracy: 0.7275\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 55s - loss: 0.4799 - binary_accuracy: 0.7566 - val_loss: 0.5253 - val_binary_accuracy: 0.7211\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.51394 to 0.51127, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-26-0.51.hdf5\n",
      " - 60s - loss: 0.4786 - binary_accuracy: 0.7544 - val_loss: 0.5113 - val_binary_accuracy: 0.7259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 55s - loss: 0.4780 - binary_accuracy: 0.7551 - val_loss: 0.5227 - val_binary_accuracy: 0.7334\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 55s - loss: 0.4753 - binary_accuracy: 0.7592 - val_loss: 0.5245 - val_binary_accuracy: 0.7345\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 55s - loss: 0.4737 - binary_accuracy: 0.7598 - val_loss: 0.5220 - val_binary_accuracy: 0.7264\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 55s - loss: 0.4719 - binary_accuracy: 0.7587 - val_loss: 0.5201 - val_binary_accuracy: 0.7383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27b24035d68>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic 1D Conv CNN LSTM\n",
    "\n",
    "start_target_size = (672)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/y_train.npy')\n",
    "\n",
    "\n",
    "# model\n",
    "inputs = Input(shape=[start_target_size])\n",
    "x = Embedding(input_dim = 5, output_dim=16, mask_zero=False, input_length=start_target_size)(inputs)\n",
    "x = Conv1D(64, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x2 = Conv1D(64, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x = Concatenate()([x, x2])\n",
    "x = MaxPooling1D(pool_size=4, strides=4)(x)\n",
    "x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs = predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=0.001, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "root_path = 'D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights'\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(root_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=1, \n",
    "                                             save_best_only=True,\n",
    "                                             save_weights_only=False,\n",
    "                                             mode='auto',\n",
    "                                             period=1)\n",
    "\n",
    "csv_path = os.path.join(root_path, 'training_history.csv')\n",
    "csv_logger = CSVLogger(csv_path, separator=',', append=False)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 672)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 672, 16)      80          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 672, 64)      16448       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 672, 64)      65600       conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 672, 128)     0           conv1d_9[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 84, 128)      0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 84, 256)      264192      max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 21504)        0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1024)         22021120    flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,368,465\n",
      "Trainable params: 22,368,465\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68965, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-01-0.69.hdf5\n",
      " - 37s - loss: 0.6917 - binary_accuracy: 0.5214 - val_loss: 0.6897 - val_binary_accuracy: 0.5245\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68965 to 0.68341, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-02-0.68.hdf5\n",
      " - 35s - loss: 0.6877 - binary_accuracy: 0.5431 - val_loss: 0.6834 - val_binary_accuracy: 0.5455\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.68341 to 0.67323, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-03-0.67.hdf5\n",
      " - 34s - loss: 0.6804 - binary_accuracy: 0.5661 - val_loss: 0.6732 - val_binary_accuracy: 0.5999\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.67323 to 0.64835, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-04-0.65.hdf5\n",
      " - 34s - loss: 0.6643 - binary_accuracy: 0.6062 - val_loss: 0.6483 - val_binary_accuracy: 0.6279\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.64835 to 0.62188, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-05-0.62.hdf5\n",
      " - 35s - loss: 0.6263 - binary_accuracy: 0.6472 - val_loss: 0.6219 - val_binary_accuracy: 0.6527\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.62188 to 0.58346, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-06-0.58.hdf5\n",
      " - 35s - loss: 0.5870 - binary_accuracy: 0.6867 - val_loss: 0.5835 - val_binary_accuracy: 0.6861\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.58346 to 0.56608, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-07-0.57.hdf5\n",
      " - 34s - loss: 0.5655 - binary_accuracy: 0.7007 - val_loss: 0.5661 - val_binary_accuracy: 0.6963\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 33s - loss: 0.5548 - binary_accuracy: 0.7122 - val_loss: 0.5693 - val_binary_accuracy: 0.6817\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.56608 to 0.55837, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-09-0.56.hdf5\n",
      " - 35s - loss: 0.5440 - binary_accuracy: 0.7136 - val_loss: 0.5584 - val_binary_accuracy: 0.6979\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.55837 to 0.54366, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-10-0.54.hdf5\n",
      " - 35s - loss: 0.5361 - binary_accuracy: 0.7220 - val_loss: 0.5437 - val_binary_accuracy: 0.7081\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.54366 to 0.54293, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-11-0.54.hdf5\n",
      " - 35s - loss: 0.5274 - binary_accuracy: 0.7312 - val_loss: 0.5429 - val_binary_accuracy: 0.7076\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.54293 to 0.53412, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-12-0.53.hdf5\n",
      " - 34s - loss: 0.5241 - binary_accuracy: 0.7314 - val_loss: 0.5341 - val_binary_accuracy: 0.7270\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 33s - loss: 0.5173 - binary_accuracy: 0.7361 - val_loss: 0.5536 - val_binary_accuracy: 0.6990\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 33s - loss: 0.5138 - binary_accuracy: 0.7366 - val_loss: 0.5433 - val_binary_accuracy: 0.7076\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.53412 to 0.53034, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-15-0.53.hdf5\n",
      " - 35s - loss: 0.5098 - binary_accuracy: 0.7404 - val_loss: 0.5303 - val_binary_accuracy: 0.7270\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.53034 to 0.52429, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-16-0.52.hdf5\n",
      " - 35s - loss: 0.5053 - binary_accuracy: 0.7440 - val_loss: 0.5243 - val_binary_accuracy: 0.7243\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.52429 to 0.52046, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-17-0.52.hdf5\n",
      " - 35s - loss: 0.5042 - binary_accuracy: 0.7446 - val_loss: 0.5205 - val_binary_accuracy: 0.7329\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 33s - loss: 0.5018 - binary_accuracy: 0.7426 - val_loss: 0.5257 - val_binary_accuracy: 0.7270\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.52046 to 0.51701, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-19-0.52.hdf5\n",
      " - 36s - loss: 0.4977 - binary_accuracy: 0.7478 - val_loss: 0.5170 - val_binary_accuracy: 0.7329\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 33s - loss: 0.4958 - binary_accuracy: 0.7469 - val_loss: 0.5253 - val_binary_accuracy: 0.7340\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 33s - loss: 0.4932 - binary_accuracy: 0.7463 - val_loss: 0.5331 - val_binary_accuracy: 0.7286\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 33s - loss: 0.4905 - binary_accuracy: 0.7509 - val_loss: 0.5216 - val_binary_accuracy: 0.7313\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 33s - loss: 0.4885 - binary_accuracy: 0.7477 - val_loss: 0.5249 - val_binary_accuracy: 0.7200\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.51701 to 0.51464, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-24-0.51.hdf5\n",
      " - 35s - loss: 0.4859 - binary_accuracy: 0.7504 - val_loss: 0.5146 - val_binary_accuracy: 0.7351\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 33s - loss: 0.4843 - binary_accuracy: 0.7515 - val_loss: 0.5524 - val_binary_accuracy: 0.7205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 33s - loss: 0.4838 - binary_accuracy: 0.7531 - val_loss: 0.5189 - val_binary_accuracy: 0.7318\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.51464 to 0.51397, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-27-0.51.hdf5\n",
      " - 35s - loss: 0.4817 - binary_accuracy: 0.7546 - val_loss: 0.5140 - val_binary_accuracy: 0.7281\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.51397 to 0.51001, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-28-0.51.hdf5\n",
      " - 35s - loss: 0.4780 - binary_accuracy: 0.7552 - val_loss: 0.5100 - val_binary_accuracy: 0.7464\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 33s - loss: 0.4790 - binary_accuracy: 0.7536 - val_loss: 0.5161 - val_binary_accuracy: 0.7394\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 33s - loss: 0.4761 - binary_accuracy: 0.7581 - val_loss: 0.5398 - val_binary_accuracy: 0.7027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d2815f518>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic 1D Conv CNN LSTM\n",
    "\n",
    "start_target_size = (672)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/y_train.npy')\n",
    "\n",
    "\n",
    "# model\n",
    "inputs = Input(shape=[start_target_size])\n",
    "x = Embedding(input_dim = 5, output_dim=16, mask_zero=False, input_length=start_target_size)(inputs)\n",
    "x = Conv1D(64, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x2 = Conv1D(64, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x = Concatenate()([x, x2])\n",
    "x = MaxPooling1D(pool_size=8, strides=8)(x)\n",
    "x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs = predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=0.001, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "root_path = 'D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights'\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(root_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=1, \n",
    "                                             save_best_only=True,\n",
    "                                             save_weights_only=False,\n",
    "                                             mode='auto',\n",
    "                                             period=1)\n",
    "\n",
    "csv_path = os.path.join(root_path, 'training_history.csv')\n",
    "csv_logger = CSVLogger(csv_path, separator=',', append=False)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 672)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 672, 16)      80          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 672, 64)      16448       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 672, 64)      65600       conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 672, 128)     0           conv1d_11[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 42, 128)      0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 42, 128)      99328       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 5376)         0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1024)         5506048     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            1025        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,688,529\n",
      "Trainable params: 5,688,529\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68960, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-01-0.69.hdf5\n",
      " - 20s - loss: 0.6914 - binary_accuracy: 0.5199 - val_loss: 0.6896 - val_binary_accuracy: 0.5574\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68960 to 0.68309, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-02-0.68.hdf5\n",
      " - 18s - loss: 0.6876 - binary_accuracy: 0.5429 - val_loss: 0.6831 - val_binary_accuracy: 0.5617\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.68309 to 0.66811, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-03-0.67.hdf5\n",
      " - 18s - loss: 0.6796 - binary_accuracy: 0.5654 - val_loss: 0.6681 - val_binary_accuracy: 0.6295\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.66811 to 0.62673, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-04-0.63.hdf5\n",
      " - 18s - loss: 0.6528 - binary_accuracy: 0.6175 - val_loss: 0.6267 - val_binary_accuracy: 0.6435\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 18s - loss: 0.6135 - binary_accuracy: 0.6658 - val_loss: 0.6532 - val_binary_accuracy: 0.6268\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.62673 to 0.57917, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-06-0.58.hdf5\n",
      " - 18s - loss: 0.5811 - binary_accuracy: 0.6897 - val_loss: 0.5792 - val_binary_accuracy: 0.6920\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.57917 to 0.55622, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-07-0.56.hdf5\n",
      " - 18s - loss: 0.5632 - binary_accuracy: 0.7026 - val_loss: 0.5562 - val_binary_accuracy: 0.7108\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 18s - loss: 0.5500 - binary_accuracy: 0.7147 - val_loss: 0.5634 - val_binary_accuracy: 0.7017\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 18s - loss: 0.5420 - binary_accuracy: 0.7213 - val_loss: 0.5598 - val_binary_accuracy: 0.7097\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.55622 to 0.54745, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-10-0.55.hdf5\n",
      " - 18s - loss: 0.5356 - binary_accuracy: 0.7225 - val_loss: 0.5475 - val_binary_accuracy: 0.7092\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 18s - loss: 0.5282 - binary_accuracy: 0.7294 - val_loss: 0.5522 - val_binary_accuracy: 0.6963\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.54745 to 0.53434, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-12-0.53.hdf5\n",
      " - 18s - loss: 0.5240 - binary_accuracy: 0.7291 - val_loss: 0.5343 - val_binary_accuracy: 0.7281\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.53434 to 0.53021, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-13-0.53.hdf5\n",
      " - 18s - loss: 0.5195 - binary_accuracy: 0.7353 - val_loss: 0.5302 - val_binary_accuracy: 0.7313\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 18s - loss: 0.5159 - binary_accuracy: 0.7398 - val_loss: 0.5347 - val_binary_accuracy: 0.7076\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.53021 to 0.52252, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-15-0.52.hdf5\n",
      " - 18s - loss: 0.5115 - binary_accuracy: 0.7390 - val_loss: 0.5225 - val_binary_accuracy: 0.7307\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 18s - loss: 0.5062 - binary_accuracy: 0.7422 - val_loss: 0.5275 - val_binary_accuracy: 0.7281\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.52252 to 0.52100, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-17-0.52.hdf5\n",
      " - 18s - loss: 0.5059 - binary_accuracy: 0.7443 - val_loss: 0.5210 - val_binary_accuracy: 0.7297\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.52100 to 0.51539, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-18-0.52.hdf5\n",
      " - 18s - loss: 0.5037 - binary_accuracy: 0.7445 - val_loss: 0.5154 - val_binary_accuracy: 0.7377\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.51539 to 0.51450, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-19-0.51.hdf5\n",
      " - 18s - loss: 0.5005 - binary_accuracy: 0.7435 - val_loss: 0.5145 - val_binary_accuracy: 0.7356\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 18s - loss: 0.4997 - binary_accuracy: 0.7465 - val_loss: 0.5273 - val_binary_accuracy: 0.7281\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 18s - loss: 0.4954 - binary_accuracy: 0.7481 - val_loss: 0.5227 - val_binary_accuracy: 0.7178\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 18s - loss: 0.4942 - binary_accuracy: 0.7513 - val_loss: 0.5202 - val_binary_accuracy: 0.7329\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 18s - loss: 0.4928 - binary_accuracy: 0.7481 - val_loss: 0.5177 - val_binary_accuracy: 0.7194\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 18s - loss: 0.4887 - binary_accuracy: 0.7478 - val_loss: 0.5147 - val_binary_accuracy: 0.7388\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.51450 to 0.51423, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-25-0.51.hdf5\n",
      " - 19s - loss: 0.4872 - binary_accuracy: 0.7498 - val_loss: 0.5142 - val_binary_accuracy: 0.7383\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 18s - loss: 0.4847 - binary_accuracy: 0.7554 - val_loss: 0.5200 - val_binary_accuracy: 0.7302\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 18s - loss: 0.4846 - binary_accuracy: 0.7516 - val_loss: 0.5187 - val_binary_accuracy: 0.7318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.51423 to 0.51230, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-28-0.51.hdf5\n",
      " - 18s - loss: 0.4817 - binary_accuracy: 0.7572 - val_loss: 0.5123 - val_binary_accuracy: 0.7372\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 18s - loss: 0.4810 - binary_accuracy: 0.7553 - val_loss: 0.5156 - val_binary_accuracy: 0.7189\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.51230 to 0.50885, saving model to D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-30-0.51.hdf5\n",
      " - 18s - loss: 0.4797 - binary_accuracy: 0.7563 - val_loss: 0.5088 - val_binary_accuracy: 0.7383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d2ecc1e80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic 1D Conv CNN LSTM\n",
    "\n",
    "start_target_size = (672)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/y_train.npy')\n",
    "\n",
    "\n",
    "# model\n",
    "inputs = Input(shape=[start_target_size])\n",
    "x = Embedding(input_dim = 5, output_dim=16, mask_zero=False, input_length=start_target_size)(inputs)\n",
    "x = Conv1D(64, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x2 = Conv1D(64, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x = Concatenate()([x, x2])\n",
    "x = MaxPooling1D(pool_size=16, strides=16)(x)\n",
    "x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs = predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=0.001, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "root_path = 'D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights'\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(root_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=1, \n",
    "                                             save_best_only=True,\n",
    "                                             save_weights_only=False,\n",
    "                                             mode='auto',\n",
    "                                             period=1)\n",
    "\n",
    "csv_path = os.path.join(root_path, 'training_history.csv')\n",
    "csv_logger = CSVLogger(csv_path, separator=',', append=False)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/x_test.npy')\n",
    "y_test = np.load('D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/y_test.npy')\n",
    "\n",
    "model_list = ['D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-29-0.52.hdf5',\n",
    "              'D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights/weights-26-0.51.hdf5',\n",
    "              'D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights/weights-28-0.51.hdf5',\n",
    "              'D:/Projects/iSynPro/iSynPro/EmbeddedSeqCNNLSTM/weights\\weights-30-0.51.hdf5'\n",
    "              ]\n",
    "label_list = ['Vanilla Embedded CNN-LSTM', \n",
    "              'Dual-Conv Embedded HalfPool CNN-LSTM',\n",
    "              'Dual-Conv Embedded CNN-LSTM',\n",
    "              'Dual-Conv Embedded DoublePool CNN-LSTM'\n",
    "              ]\n",
    "roc_list = []\n",
    "for path in model_list:\n",
    "    model = load_model(path)\n",
    "    y_pred = model.predict(x_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_list.append([fpr, tpr, auc])\n",
    "    K.clear_session()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ae164a3ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "palette = sns.color_palette(\"cubehelix\", len(roc_list))\n",
    "\n",
    "#plot roc curve\n",
    "for i in range(len(roc_list)):\n",
    "    plt.plot(roc_list[i][0], \n",
    "             roc_list[i][1], \n",
    "             color=palette[i], \n",
    "             label='{0} (AUC = {1:.3f})'.format(label_list[i], roc_list[i][2]))\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Embedded Sequence CNN-LSTMs')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('d:/projects/isynpro/SyntheticPromoter/readme_figures/embedded_roc.png', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
