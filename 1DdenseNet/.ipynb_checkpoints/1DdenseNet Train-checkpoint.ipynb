{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D DenseNet CNN\n",
    "Similar to the architecture in this paper: https://arxiv.org/abs/1608.06993\n",
    "Adapted to a truncated, 1D version for our purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from keras.layers import Conv2D, BatchNormalization, Dense, Dropout, Activation, AveragePooling1D, GaussianNoise\n",
    "from keras.layers import Input, Concatenate, Flatten, Conv1D, MaxPooling1D, Reshape, SeparableConv1D\n",
    "from keras.layers import GlobalMaxPooling1D, Lambda, GlobalAveragePooling1D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our data\n",
    "start_target_size = (672, 4)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_train.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 672, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNoise (None, 672, 4)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 336, 512)     14848       gaussian_noise_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 167, 512)     0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 167, 64)      32832       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 167, 64)      256         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 167, 64)      12352       batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 167, 64)      256         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 167, 64)      256         batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 167, 64)      4160        batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 167, 64)      256         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 167, 64)      12352       batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 167, 64)      256         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 167, 64)      256         batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 167, 128)     0           batch_normalization_53[0][0]     \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 167, 64)      8256        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 167, 64)      256         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 167, 64)      12352       batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 167, 64)      256         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 167, 64)      256         batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 167, 192)     0           batch_normalization_53[0][0]     \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 167, 64)      12352       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 167, 64)      256         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 167, 64)      12352       batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 167, 64)      256         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 167, 64)      256         batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 167, 256)     0           batch_normalization_53[0][0]     \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_59[0][0]     \n",
      "                                                                 batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 167, 64)      16448       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 167, 64)      256         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 167, 64)      12352       batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 167, 64)      256         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 167, 64)      256         batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 167, 320)     0           batch_normalization_53[0][0]     \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_59[0][0]     \n",
      "                                                                 batch_normalization_62[0][0]     \n",
      "                                                                 batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 167, 64)      20544       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 167, 64)      256         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 167, 64)      12352       batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 167, 64)      256         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 167, 64)      256         batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 167, 64)      4160        batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 83, 64)       0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 83, 64)       4160        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 83, 64)       256         conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 83, 64)       12352       batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 83, 64)       256         conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 83, 64)       256         batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 83, 64)       4160        batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 83, 64)       256         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 83, 64)       12352       batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 83, 64)       256         conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 83, 64)       256         batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 83, 128)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 83, 64)       8256        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 83, 64)       256         conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 83, 64)       12352       batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 83, 64)       256         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 83, 64)       256         batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 83, 192)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 83, 64)       12352       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 83, 64)       256         conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 83, 64)       12352       batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 83, 64)       256         conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 83, 64)       256         batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 83, 256)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 83, 64)       16448       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 83, 64)       256         conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 83, 64)       12352       batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 83, 64)       256         conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 83, 64)       256         batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 83, 320)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 83, 64)       20544       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 83, 64)       256         conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 83, 64)       12352       batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 83, 64)       256         conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 83, 64)       256         batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 83, 384)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 83, 64)       24640       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 83, 64)       256         conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 83, 64)       12352       batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 83, 64)       256         conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 83, 64)       256         batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 83, 448)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 83, 64)       28736       concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 83, 64)       256         conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 83, 64)       12352       batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 83, 64)       256         conv1d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 83, 64)       256         batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 83, 512)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 83, 64)       32832       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 83, 64)       256         conv1d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 83, 64)       12352       batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 83, 64)       256         conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 83, 64)       256         batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 83, 576)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 83, 64)       36928       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 83, 64)       256         conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 83, 64)       12352       batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 83, 64)       256         conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 83, 64)       256         batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 83, 640)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "                                                                 batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 83, 64)       41024       concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 83, 64)       256         conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 83, 64)       12352       batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 83, 64)       256         conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 83, 64)       256         batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 83, 704)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "                                                                 batch_normalization_98[0][0]     \n",
      "                                                                 batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 83, 64)       45120       concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 83, 64)       256         conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 83, 64)       12352       batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 83, 64)       256         conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 83, 64)       256         batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 83, 64)       4160        batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 5312)         0           conv1d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         5440512     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1025        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,070,657\n",
      "Trainable params: 6,063,745\n",
      "Non-trainable params: 6,912\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60291, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-01-0.60.hdf5\n",
      " - 103s - loss: 0.6707 - binary_accuracy: 0.6052 - val_loss: 0.6029 - val_binary_accuracy: 0.6419\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60291 to 0.56998, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-02-0.57.hdf5\n",
      " - 74s - loss: 0.5980 - binary_accuracy: 0.6691 - val_loss: 0.5700 - val_binary_accuracy: 0.7006\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56998 to 0.56154, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-03-0.56.hdf5\n",
      " - 73s - loss: 0.5779 - binary_accuracy: 0.6883 - val_loss: 0.5615 - val_binary_accuracy: 0.7054\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56154 to 0.55106, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-04-0.55.hdf5\n",
      " - 73s - loss: 0.5645 - binary_accuracy: 0.6958 - val_loss: 0.5511 - val_binary_accuracy: 0.7092\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55106 to 0.54524, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-05-0.55.hdf5\n",
      " - 73s - loss: 0.5577 - binary_accuracy: 0.7033 - val_loss: 0.5452 - val_binary_accuracy: 0.7162\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54524 to 0.53782, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-06-0.54.hdf5\n",
      " - 73s - loss: 0.5477 - binary_accuracy: 0.7110 - val_loss: 0.5378 - val_binary_accuracy: 0.7135\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 73s - loss: 0.5416 - binary_accuracy: 0.7153 - val_loss: 0.5398 - val_binary_accuracy: 0.7243\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 73s - loss: 0.5363 - binary_accuracy: 0.7222 - val_loss: 0.5380 - val_binary_accuracy: 0.7259\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.53782 to 0.53036, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-09-0.53.hdf5\n",
      " - 73s - loss: 0.5335 - binary_accuracy: 0.7267 - val_loss: 0.5304 - val_binary_accuracy: 0.7286\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 72s - loss: 0.5268 - binary_accuracy: 0.7267 - val_loss: 0.5307 - val_binary_accuracy: 0.7351\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 75s - loss: 0.5253 - binary_accuracy: 0.7302 - val_loss: 0.5343 - val_binary_accuracy: 0.7254\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 72s - loss: 0.5233 - binary_accuracy: 0.7322 - val_loss: 0.5400 - val_binary_accuracy: 0.7243\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 72s - loss: 0.5184 - binary_accuracy: 0.7352 - val_loss: 0.5390 - val_binary_accuracy: 0.7291\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.53036 to 0.52981, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-14-0.53.hdf5\n",
      " - 73s - loss: 0.5171 - binary_accuracy: 0.7377 - val_loss: 0.5298 - val_binary_accuracy: 0.7264\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 73s - loss: 0.5161 - binary_accuracy: 0.7371 - val_loss: 0.5306 - val_binary_accuracy: 0.7297\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.52981 to 0.52043, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-16-0.52.hdf5\n",
      " - 73s - loss: 0.5124 - binary_accuracy: 0.7379 - val_loss: 0.5204 - val_binary_accuracy: 0.7286\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 72s - loss: 0.5108 - binary_accuracy: 0.7414 - val_loss: 0.5208 - val_binary_accuracy: 0.7329\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 72s - loss: 0.5108 - binary_accuracy: 0.7399 - val_loss: 0.5326 - val_binary_accuracy: 0.7297\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.52043 to 0.51961, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-19-0.52.hdf5\n",
      " - 73s - loss: 0.5069 - binary_accuracy: 0.7422 - val_loss: 0.5196 - val_binary_accuracy: 0.7340\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 72s - loss: 0.5060 - binary_accuracy: 0.7437 - val_loss: 0.5247 - val_binary_accuracy: 0.7318\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 72s - loss: 0.5039 - binary_accuracy: 0.7464 - val_loss: 0.5250 - val_binary_accuracy: 0.7307\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 72s - loss: 0.5037 - binary_accuracy: 0.7462 - val_loss: 0.5225 - val_binary_accuracy: 0.7281\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 72s - loss: 0.5020 - binary_accuracy: 0.7440 - val_loss: 0.5267 - val_binary_accuracy: 0.7270\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 72s - loss: 0.4995 - binary_accuracy: 0.7471 - val_loss: 0.5202 - val_binary_accuracy: 0.7211\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 72s - loss: 0.4986 - binary_accuracy: 0.7485 - val_loss: 0.5210 - val_binary_accuracy: 0.7302\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 72s - loss: 0.4985 - binary_accuracy: 0.7492 - val_loss: 0.5279 - val_binary_accuracy: 0.7281\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 72s - loss: 0.4962 - binary_accuracy: 0.7491 - val_loss: 0.5310 - val_binary_accuracy: 0.7221\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 72s - loss: 0.4942 - binary_accuracy: 0.7495 - val_loss: 0.5271 - val_binary_accuracy: 0.7302\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.51961 to 0.51893, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-29-0.52.hdf5\n",
      " - 73s - loss: 0.4931 - binary_accuracy: 0.7522 - val_loss: 0.5189 - val_binary_accuracy: 0.7302\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 73s - loss: 0.4902 - binary_accuracy: 0.7502 - val_loss: 0.5269 - val_binary_accuracy: 0.7259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a8c1cf1518>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D Densenet\n",
    "\n",
    "#set of conv blocks wrapper\n",
    "def conv_block(x, dim):\n",
    "    x1 = Conv1D(dim, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Conv1D(dim, kernel_size=3, strides=1, padding='same', activation='relu')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    return x1\n",
    "\n",
    "# dense block wrapper\n",
    "def dense_block(inlayer, convs, dims):\n",
    "    conv_list = []\n",
    "    ministem = conv_block(inlayer, dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    ministem = conv_block(conv_list[0], dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    for _ in range(convs-2):\n",
    "        x = Concatenate()([layer for layer in conv_list])\n",
    "        x = conv_block(x, dims)\n",
    "        x = BatchNormalization()(x)\n",
    "        conv_list.append(x)\n",
    "    return conv_list[-1]\n",
    "\n",
    "## build our model\n",
    "# stem\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x = Conv1D(512, kernel_size=7, strides=2, padding='same', activation='relu')(x)\n",
    "x = MaxPooling1D(pool_size=3, strides=2)(x)\n",
    "    \n",
    "# dense block 1\n",
    "d1 = dense_block(x, 6, 64)\n",
    "\n",
    "#transition\n",
    "t = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d1)\n",
    "t = MaxPooling1D(pool_size=2, strides=2)(t)\n",
    "\n",
    "# dense block 2\n",
    "d2 = dense_block(t, 12, 64)\n",
    "\n",
    "# optional depth, doesn't seem to help\n",
    "'''\n",
    "#transition\n",
    "t2 = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "t2 = AveragePooling1D(pool_size=2, strides=2)(t2)\n",
    "\n",
    "# dense block 2\n",
    "d3 = dense_block(t2, 6, 64)\n",
    "'''\n",
    "\n",
    "# exit stem\n",
    "fc = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "fc = Flatten()(fc)\n",
    "fc = Dense(1024, activation='relu')(fc)\n",
    "fc = Dropout(0.5)(fc)\n",
    "predictions = Dense(1, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 672, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_5 (GaussianNoise (None, 672, 4)       0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 336, 512)     14848       gaussian_noise_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 167, 512)     0           conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_37 (SeparableC (None, 167, 64)      33344       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 167, 64)      256         separable_conv1d_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_38 (SeparableC (None, 167, 64)      4352        batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 167, 64)      256         separable_conv1d_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 167, 64)      256         batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_39 (SeparableC (None, 167, 64)      4224        batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 167, 64)      256         separable_conv1d_39[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_40 (SeparableC (None, 167, 64)      4352        batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 167, 64)      256         separable_conv1d_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 167, 64)      256         batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 167, 128)     0           batch_normalization_161[0][0]    \n",
      "                                                                 batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_41 (SeparableC (None, 167, 64)      8384        concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 167, 64)      256         separable_conv1d_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_42 (SeparableC (None, 167, 64)      4352        batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 167, 64)      256         separable_conv1d_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 167, 64)      256         batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 167, 192)     0           batch_normalization_161[0][0]    \n",
      "                                                                 batch_normalization_164[0][0]    \n",
      "                                                                 batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_43 (SeparableC (None, 167, 64)      12544       concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 167, 64)      256         separable_conv1d_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_44 (SeparableC (None, 167, 64)      4352        batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 167, 64)      256         separable_conv1d_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 167, 64)      256         batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 167, 256)     0           batch_normalization_161[0][0]    \n",
      "                                                                 batch_normalization_164[0][0]    \n",
      "                                                                 batch_normalization_167[0][0]    \n",
      "                                                                 batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_45 (SeparableC (None, 167, 64)      16704       concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 167, 64)      256         separable_conv1d_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_46 (SeparableC (None, 167, 64)      4352        batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 167, 64)      256         separable_conv1d_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 167, 64)      256         batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 167, 320)     0           batch_normalization_161[0][0]    \n",
      "                                                                 batch_normalization_164[0][0]    \n",
      "                                                                 batch_normalization_167[0][0]    \n",
      "                                                                 batch_normalization_170[0][0]    \n",
      "                                                                 batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_47 (SeparableC (None, 167, 64)      20864       concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 167, 64)      256         separable_conv1d_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_48 (SeparableC (None, 167, 64)      4352        batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 167, 64)      256         separable_conv1d_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 167, 64)      256         batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 167, 64)      4160        batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 83, 64)       0           conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_49 (SeparableC (None, 83, 64)       4224        max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 83, 64)       256         separable_conv1d_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_50 (SeparableC (None, 83, 64)       4352        batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 83, 64)       256         separable_conv1d_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 83, 64)       256         batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_51 (SeparableC (None, 83, 64)       4224        batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 83, 64)       256         separable_conv1d_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_52 (SeparableC (None, 83, 64)       4352        batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 83, 64)       256         separable_conv1d_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 83, 64)       256         batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 83, 128)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_53 (SeparableC (None, 83, 64)       8384        concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 83, 64)       256         separable_conv1d_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_54 (SeparableC (None, 83, 64)       4352        batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 83, 64)       256         separable_conv1d_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 83, 64)       256         batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 83, 192)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_55 (SeparableC (None, 83, 64)       12544       concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 83, 64)       256         separable_conv1d_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_56 (SeparableC (None, 83, 64)       4352        batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 83, 64)       256         separable_conv1d_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 83, 64)       256         batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 83, 256)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_57 (SeparableC (None, 83, 64)       16704       concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 83, 64)       256         separable_conv1d_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_58 (SeparableC (None, 83, 64)       4352        batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 83, 64)       256         separable_conv1d_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 83, 64)       256         batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 83, 320)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_59 (SeparableC (None, 83, 64)       20864       concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 83, 64)       256         separable_conv1d_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_60 (SeparableC (None, 83, 64)       4352        batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 83, 64)       256         separable_conv1d_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 83, 64)       256         batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 83, 384)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_61 (SeparableC (None, 83, 64)       25024       concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 83, 64)       256         separable_conv1d_61[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_62 (SeparableC (None, 83, 64)       4352        batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 83, 64)       256         separable_conv1d_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 83, 64)       256         batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 83, 448)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_63 (SeparableC (None, 83, 64)       29184       concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 83, 64)       256         separable_conv1d_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_64 (SeparableC (None, 83, 64)       4352        batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 83, 64)       256         separable_conv1d_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 83, 64)       256         batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 83, 512)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "                                                                 batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_65 (SeparableC (None, 83, 64)       33344       concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 83, 64)       256         separable_conv1d_65[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_66 (SeparableC (None, 83, 64)       4352        batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 83, 64)       256         separable_conv1d_66[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 83, 64)       256         batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 83, 576)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "                                                                 batch_normalization_200[0][0]    \n",
      "                                                                 batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_67 (SeparableC (None, 83, 64)       37504       concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 83, 64)       256         separable_conv1d_67[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_68 (SeparableC (None, 83, 64)       4352        batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 83, 64)       256         separable_conv1d_68[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 83, 64)       256         batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 83, 640)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "                                                                 batch_normalization_200[0][0]    \n",
      "                                                                 batch_normalization_203[0][0]    \n",
      "                                                                 batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_69 (SeparableC (None, 83, 64)       41664       concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 83, 64)       256         separable_conv1d_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_70 (SeparableC (None, 83, 64)       4352        batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 83, 64)       256         separable_conv1d_70[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 83, 64)       256         batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 83, 704)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "                                                                 batch_normalization_200[0][0]    \n",
      "                                                                 batch_normalization_203[0][0]    \n",
      "                                                                 batch_normalization_206[0][0]    \n",
      "                                                                 batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_71 (SeparableC (None, 83, 64)       45824       concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 83, 64)       256         separable_conv1d_71[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_72 (SeparableC (None, 83, 64)       4352        batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 83, 64)       256         separable_conv1d_72[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 83, 64)       256         batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 83, 64)       4160        batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 5312)         0           conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1024)         5440512     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,932,417\n",
      "Trainable params: 5,925,505\n",
      "Non-trainable params: 6,912\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63842, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-01-0.64.hdf5\n",
      " - 134s - loss: 0.7047 - binary_accuracy: 0.5651 - val_loss: 0.6384 - val_binary_accuracy: 0.6187\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63842 to 0.57821, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-02-0.58.hdf5\n",
      " - 83s - loss: 0.6164 - binary_accuracy: 0.6566 - val_loss: 0.5782 - val_binary_accuracy: 0.6834\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57821 to 0.57262, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-03-0.57.hdf5\n",
      " - 83s - loss: 0.5940 - binary_accuracy: 0.6791 - val_loss: 0.5726 - val_binary_accuracy: 0.6920\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57262 to 0.56834, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-04-0.57.hdf5\n",
      " - 83s - loss: 0.5809 - binary_accuracy: 0.6842 - val_loss: 0.5683 - val_binary_accuracy: 0.6979\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56834 to 0.56248, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-05-0.56.hdf5\n",
      " - 83s - loss: 0.5699 - binary_accuracy: 0.6967 - val_loss: 0.5625 - val_binary_accuracy: 0.6952\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 82s - loss: 0.5624 - binary_accuracy: 0.7036 - val_loss: 0.5728 - val_binary_accuracy: 0.7081\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.56248 to 0.55794, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-07-0.56.hdf5\n",
      " - 83s - loss: 0.5593 - binary_accuracy: 0.7063 - val_loss: 0.5579 - val_binary_accuracy: 0.7033\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55794 to 0.55688, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-08-0.56.hdf5\n",
      " - 83s - loss: 0.5518 - binary_accuracy: 0.7113 - val_loss: 0.5569 - val_binary_accuracy: 0.7017\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 82s - loss: 0.5487 - binary_accuracy: 0.7119 - val_loss: 0.5589 - val_binary_accuracy: 0.7076\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.55688 to 0.54655, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-10-0.55.hdf5\n",
      " - 83s - loss: 0.5426 - binary_accuracy: 0.7179 - val_loss: 0.5466 - val_binary_accuracy: 0.7173\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.54655 to 0.54075, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-11-0.54.hdf5\n",
      " - 83s - loss: 0.5367 - binary_accuracy: 0.7204 - val_loss: 0.5407 - val_binary_accuracy: 0.7216\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.54075 to 0.53277, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-12-0.53.hdf5\n",
      " - 83s - loss: 0.5339 - binary_accuracy: 0.7233 - val_loss: 0.5328 - val_binary_accuracy: 0.7216\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 82s - loss: 0.5300 - binary_accuracy: 0.7225 - val_loss: 0.5385 - val_binary_accuracy: 0.7135\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 82s - loss: 0.5286 - binary_accuracy: 0.7295 - val_loss: 0.5363 - val_binary_accuracy: 0.7221\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 82s - loss: 0.5239 - binary_accuracy: 0.7289 - val_loss: 0.5405 - val_binary_accuracy: 0.7254\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 83s - loss: 0.5208 - binary_accuracy: 0.7320 - val_loss: 0.5390 - val_binary_accuracy: 0.7216\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 83s - loss: 0.5198 - binary_accuracy: 0.7333 - val_loss: 0.5346 - val_binary_accuracy: 0.7270\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 83s - loss: 0.5161 - binary_accuracy: 0.7352 - val_loss: 0.5382 - val_binary_accuracy: 0.7248\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.53277 to 0.53222, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-19-0.53.hdf5\n",
      " - 84s - loss: 0.5158 - binary_accuracy: 0.7386 - val_loss: 0.5322 - val_binary_accuracy: 0.7248\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 83s - loss: 0.5143 - binary_accuracy: 0.7387 - val_loss: 0.5363 - val_binary_accuracy: 0.7216\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 83s - loss: 0.5094 - binary_accuracy: 0.7413 - val_loss: 0.5401 - val_binary_accuracy: 0.7205\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.53222 to 0.52935, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-22-0.53.hdf5\n",
      " - 84s - loss: 0.5091 - binary_accuracy: 0.7400 - val_loss: 0.5293 - val_binary_accuracy: 0.7232\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 83s - loss: 0.5052 - binary_accuracy: 0.7431 - val_loss: 0.5381 - val_binary_accuracy: 0.7221\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.52935 to 0.52665, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-24-0.53.hdf5\n",
      " - 83s - loss: 0.5039 - binary_accuracy: 0.7441 - val_loss: 0.5266 - val_binary_accuracy: 0.7178\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.52665 to 0.52223, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-25-0.52.hdf5\n",
      " - 84s - loss: 0.5023 - binary_accuracy: 0.7425 - val_loss: 0.5222 - val_binary_accuracy: 0.7243\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 83s - loss: 0.5004 - binary_accuracy: 0.7469 - val_loss: 0.5262 - val_binary_accuracy: 0.7221\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 83s - loss: 0.4999 - binary_accuracy: 0.7474 - val_loss: 0.5237 - val_binary_accuracy: 0.7243\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 83s - loss: 0.4971 - binary_accuracy: 0.7454 - val_loss: 0.5307 - val_binary_accuracy: 0.7173\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 83s - loss: 0.4987 - binary_accuracy: 0.7455 - val_loss: 0.5357 - val_binary_accuracy: 0.7194\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 82s - loss: 0.4946 - binary_accuracy: 0.7479 - val_loss: 0.5273 - val_binary_accuracy: 0.7157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a8f1f50f28>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D Densenet, with separable depthwise 1D convs\n",
    "\n",
    "#set of conv blocks wrapper\n",
    "def conv_block(x, dim):\n",
    "    x1 = SeparableConv1D(dim, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = SeparableConv1D(dim, kernel_size=3, strides=1, padding='same', activation='relu')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    return x1\n",
    "\n",
    "# dense block wrapper\n",
    "def dense_block(inlayer, convs, dims):\n",
    "    conv_list = []\n",
    "    ministem = conv_block(inlayer, dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    ministem = conv_block(conv_list[0], dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    for _ in range(convs-2):\n",
    "        x = Concatenate()([layer for layer in conv_list])\n",
    "        x = conv_block(x, dims)\n",
    "        x = BatchNormalization()(x)\n",
    "        conv_list.append(x)\n",
    "    return conv_list[-1]\n",
    "\n",
    "## build our model\n",
    "# stem\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x = Conv1D(512, kernel_size=7, strides=2, padding='same', activation='relu')(x)\n",
    "x = MaxPooling1D(pool_size=3, strides=2)(x)\n",
    "    \n",
    "# dense block 1\n",
    "d1 = dense_block(x, 6, 64)\n",
    "\n",
    "#transition\n",
    "t = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d1)\n",
    "t = MaxPooling1D(pool_size=2, strides=2)(t)\n",
    "\n",
    "# dense block 2\n",
    "d2 = dense_block(t, 12, 64)\n",
    "\n",
    "# optional depth\n",
    "'''\n",
    "#transition\n",
    "t2 = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "t2 = AveragePooling1D(pool_size=2, strides=2)(t2)\n",
    "\n",
    "# dense block 2\n",
    "d3 = dense_block(t2, 6, 64)\n",
    "'''\n",
    "\n",
    "# exit stem\n",
    "fc = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "#fc = GlobalAveragePooling1D()(fc)\n",
    "fc = Flatten()(fc)\n",
    "fc = Dense(1024, activation='relu')(fc)\n",
    "fc = Dropout(0.5)(fc)\n",
    "predictions = Dense(1, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 672, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_7 (GaussianNoise (None, 672, 4)       0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)             (None, 672, 128)     640         gaussian_noise_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 672, 128)     512         conv1d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_123 (Conv1D)             (None, 672, 128)     49280       batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 672, 128)     512         conv1d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 672, 128)     512         batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_124 (Conv1D)             (None, 672, 128)     16512       batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 672, 128)     512         conv1d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_125 (Conv1D)             (None, 672, 128)     49280       batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 672, 128)     512         conv1d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 672, 128)     512         batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 672, 256)     0           batch_normalization_269[0][0]    \n",
      "                                                                 batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_126 (Conv1D)             (None, 672, 128)     32896       concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 672, 128)     512         conv1d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_127 (Conv1D)             (None, 672, 128)     49280       batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 672, 128)     512         conv1d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 672, 128)     512         batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 672, 384)     0           batch_normalization_269[0][0]    \n",
      "                                                                 batch_normalization_272[0][0]    \n",
      "                                                                 batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_128 (Conv1D)             (None, 672, 128)     49280       concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 672, 128)     512         conv1d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_129 (Conv1D)             (None, 672, 128)     49280       batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 672, 128)     512         conv1d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 672, 128)     512         batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 672, 512)     0           batch_normalization_269[0][0]    \n",
      "                                                                 batch_normalization_272[0][0]    \n",
      "                                                                 batch_normalization_275[0][0]    \n",
      "                                                                 batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_130 (Conv1D)             (None, 672, 128)     65664       concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 672, 128)     512         conv1d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_131 (Conv1D)             (None, 672, 128)     49280       batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 672, 128)     512         conv1d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 672, 128)     512         batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 672, 640)     0           batch_normalization_269[0][0]    \n",
      "                                                                 batch_normalization_272[0][0]    \n",
      "                                                                 batch_normalization_275[0][0]    \n",
      "                                                                 batch_normalization_278[0][0]    \n",
      "                                                                 batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_132 (Conv1D)             (None, 672, 128)     82048       concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 672, 128)     512         conv1d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_133 (Conv1D)             (None, 672, 128)     49280       batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 672, 128)     512         conv1d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 672, 128)     512         batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_134 (Conv1D)             (None, 672, 128)     16512       batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 336, 128)     0           conv1d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_135 (Conv1D)             (None, 336, 64)      8256        max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 336, 64)      256         conv1d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_136 (Conv1D)             (None, 336, 64)      12352       batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 336, 64)      256         conv1d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 336, 64)      256         batch_normalization_286[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv1d_137 (Conv1D)             (None, 336, 64)      4160        batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 336, 64)      256         conv1d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_138 (Conv1D)             (None, 336, 64)      12352       batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 336, 64)      256         conv1d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 336, 64)      256         batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 336, 128)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_139 (Conv1D)             (None, 336, 64)      8256        concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 336, 64)      256         conv1d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_140 (Conv1D)             (None, 336, 64)      12352       batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 336, 64)      256         conv1d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 336, 64)      256         batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 336, 192)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_141 (Conv1D)             (None, 336, 64)      12352       concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 336, 64)      256         conv1d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_142 (Conv1D)             (None, 336, 64)      12352       batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 336, 64)      256         conv1d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 336, 64)      256         batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 336, 256)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_143 (Conv1D)             (None, 336, 64)      16448       concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 336, 64)      256         conv1d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_144 (Conv1D)             (None, 336, 64)      12352       batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 336, 64)      256         conv1d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 336, 64)      256         batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 336, 320)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_145 (Conv1D)             (None, 336, 64)      20544       concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 336, 64)      256         conv1d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_146 (Conv1D)             (None, 336, 64)      12352       batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 336, 64)      256         conv1d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 336, 64)      256         batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 336, 384)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_147 (Conv1D)             (None, 336, 64)      24640       concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 336, 64)      256         conv1d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_148 (Conv1D)             (None, 336, 64)      12352       batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 336, 64)      256         conv1d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 336, 64)      256         batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 336, 448)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "                                                                 batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_149 (Conv1D)             (None, 336, 64)      28736       concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 336, 64)      256         conv1d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_150 (Conv1D)             (None, 336, 64)      12352       batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 336, 64)      256         conv1d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 336, 64)      256         batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 336, 512)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "                                                                 batch_normalization_305[0][0]    \n",
      "                                                                 batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_151 (Conv1D)             (None, 336, 64)      32832       concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 336, 64)      256         conv1d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_152 (Conv1D)             (None, 336, 64)      12352       batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 336, 64)      256         conv1d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 336, 64)      256         batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 336, 576)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "                                                                 batch_normalization_305[0][0]    \n",
      "                                                                 batch_normalization_308[0][0]    \n",
      "                                                                 batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_153 (Conv1D)             (None, 336, 64)      36928       concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 336, 64)      256         conv1d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_154 (Conv1D)             (None, 336, 64)      12352       batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 336, 64)      256         conv1d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 336, 64)      256         batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 336, 640)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "                                                                 batch_normalization_305[0][0]    \n",
      "                                                                 batch_normalization_308[0][0]    \n",
      "                                                                 batch_normalization_311[0][0]    \n",
      "                                                                 batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_155 (Conv1D)             (None, 336, 64)      41024       concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 336, 64)      256         conv1d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_156 (Conv1D)             (None, 336, 64)      12352       batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 336, 64)      256         conv1d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 336, 64)      256         batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 336, 704)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "                                                                 batch_normalization_305[0][0]    \n",
      "                                                                 batch_normalization_308[0][0]    \n",
      "                                                                 batch_normalization_311[0][0]    \n",
      "                                                                 batch_normalization_314[0][0]    \n",
      "                                                                 batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_157 (Conv1D)             (None, 336, 64)      45120       concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 336, 64)      256         conv1d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_158 (Conv1D)             (None, 336, 64)      12352       batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 336, 64)      256         conv1d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 336, 64)      256         batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_159 (Conv1D)             (None, 336, 64)      4160        batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 168, 64)      0           conv1d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 10752)        0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         11011072    flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            1025        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,021,441\n",
      "Trainable params: 12,012,225\n",
      "Non-trainable params: 9,216\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59764, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-01-0.60.hdf5\n",
      " - 207s - loss: 0.6841 - binary_accuracy: 0.6059 - val_loss: 0.5976 - val_binary_accuracy: 0.6731\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59764 to 0.58804, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-02-0.59.hdf5\n",
      " - 144s - loss: 0.5866 - binary_accuracy: 0.6856 - val_loss: 0.5880 - val_binary_accuracy: 0.6974\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 144s - loss: 0.5672 - binary_accuracy: 0.6981 - val_loss: 0.5929 - val_binary_accuracy: 0.7151\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58804 to 0.57400, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-04-0.57.hdf5\n",
      " - 144s - loss: 0.5575 - binary_accuracy: 0.7064 - val_loss: 0.5740 - val_binary_accuracy: 0.7071\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.57400 to 0.56851, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-05-0.57.hdf5\n",
      " - 145s - loss: 0.5471 - binary_accuracy: 0.7216 - val_loss: 0.5685 - val_binary_accuracy: 0.7173\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56851 to 0.56592, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-06-0.57.hdf5\n",
      " - 145s - loss: 0.5433 - binary_accuracy: 0.7204 - val_loss: 0.5659 - val_binary_accuracy: 0.7151\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.56592 to 0.54141, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-07-0.54.hdf5\n",
      " - 145s - loss: 0.5383 - binary_accuracy: 0.7213 - val_loss: 0.5414 - val_binary_accuracy: 0.7114\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 144s - loss: 0.5326 - binary_accuracy: 0.7292 - val_loss: 0.5468 - val_binary_accuracy: 0.7173\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 144s - loss: 0.5306 - binary_accuracy: 0.7268 - val_loss: 0.5541 - val_binary_accuracy: 0.7216\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.54141 to 0.53692, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-10-0.54.hdf5\n",
      " - 145s - loss: 0.5206 - binary_accuracy: 0.7356 - val_loss: 0.5369 - val_binary_accuracy: 0.7329\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 143s - loss: 0.5141 - binary_accuracy: 0.7380 - val_loss: 0.5528 - val_binary_accuracy: 0.7313\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 143s - loss: 0.5128 - binary_accuracy: 0.7395 - val_loss: 0.5583 - val_binary_accuracy: 0.7205\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.53692 to 0.53221, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-13-0.53.hdf5\n",
      " - 144s - loss: 0.5110 - binary_accuracy: 0.7409 - val_loss: 0.5322 - val_binary_accuracy: 0.7351\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 144s - loss: 0.5070 - binary_accuracy: 0.7456 - val_loss: 0.5357 - val_binary_accuracy: 0.7297\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 143s - loss: 0.5025 - binary_accuracy: 0.7463 - val_loss: 0.5498 - val_binary_accuracy: 0.7318\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 143s - loss: 0.5022 - binary_accuracy: 0.7446 - val_loss: 0.5505 - val_binary_accuracy: 0.7313\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 143s - loss: 0.5013 - binary_accuracy: 0.7480 - val_loss: 0.5360 - val_binary_accuracy: 0.7307\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 144s - loss: 0.4994 - binary_accuracy: 0.7475 - val_loss: 0.5360 - val_binary_accuracy: 0.7318\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 144s - loss: 0.4982 - binary_accuracy: 0.7502 - val_loss: 0.5332 - val_binary_accuracy: 0.7291\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 144s - loss: 0.4923 - binary_accuracy: 0.7526 - val_loss: 0.5356 - val_binary_accuracy: 0.7361\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.53221 to 0.53062, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-21-0.53.hdf5\n",
      " - 145s - loss: 0.4905 - binary_accuracy: 0.7526 - val_loss: 0.5306 - val_binary_accuracy: 0.7313\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.53062 to 0.52804, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-22-0.53.hdf5\n",
      " - 144s - loss: 0.4923 - binary_accuracy: 0.7526 - val_loss: 0.5280 - val_binary_accuracy: 0.7291\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 144s - loss: 0.4892 - binary_accuracy: 0.7553 - val_loss: 0.5345 - val_binary_accuracy: 0.7324\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 147s - loss: 0.4878 - binary_accuracy: 0.7541 - val_loss: 0.5308 - val_binary_accuracy: 0.7281\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 145s - loss: 0.4869 - binary_accuracy: 0.7575 - val_loss: 0.5471 - val_binary_accuracy: 0.7232\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 144s - loss: 0.4825 - binary_accuracy: 0.7590 - val_loss: 0.5336 - val_binary_accuracy: 0.7302\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 146s - loss: 0.4803 - binary_accuracy: 0.7602 - val_loss: 0.5435 - val_binary_accuracy: 0.7361\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 147s - loss: 0.4799 - binary_accuracy: 0.7578 - val_loss: 0.5387 - val_binary_accuracy: 0.7307\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 145s - loss: 0.4794 - binary_accuracy: 0.7617 - val_loss: 0.5322 - val_binary_accuracy: 0.7286\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 144s - loss: 0.4773 - binary_accuracy: 0.7628 - val_loss: 0.5385 - val_binary_accuracy: 0.7297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a932ff2ba8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D Densenet with elongated beginning stem\n",
    "\n",
    "#set of conv blocks wrapper\n",
    "def conv_block(x, dim):\n",
    "    x1 = Conv1D(dim, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Conv1D(dim, kernel_size=3, strides=1, padding='same', activation='relu')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    return x1\n",
    "\n",
    "# dense block wrapper\n",
    "def dense_block(inlayer, convs, dims):\n",
    "    conv_list = []\n",
    "    ministem = conv_block(inlayer, dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    ministem = conv_block(conv_list[0], dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    for _ in range(convs-2):\n",
    "        x = Concatenate()([layer for layer in conv_list])\n",
    "        x = conv_block(x, dims)\n",
    "        x = BatchNormalization()(x)\n",
    "        conv_list.append(x)\n",
    "    return conv_list[-1]\n",
    "\n",
    "## build our model\n",
    "# stem\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "#x = Conv1D(512, kernel_size=7, strides=2, padding='same', activation='relu')(x)\n",
    "    \n",
    "# dense block 1\n",
    "d1 = dense_block(x, 6, 128)\n",
    "\n",
    "#transition\n",
    "t = Conv1D(128, kernel_size=1, strides=1, padding='same', activation='relu')(d1)\n",
    "t = MaxPooling1D(pool_size=2, strides=2)(t)\n",
    "\n",
    "# dense block 2\n",
    "d2 = dense_block(t, 12, 64)\n",
    "\n",
    "# optional depth\n",
    "'''\n",
    "#transition\n",
    "t2 = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "t2 = AveragePooling1D(pool_size=2, strides=2)(t2)\n",
    "\n",
    "# dense block 2\n",
    "d3 = dense_block(t2, 6, 64)\n",
    "'''\n",
    "\n",
    "# exit stem\n",
    "fc = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "fc = MaxPooling1D(pool_size=2, strides=2)(fc)\n",
    "fc = Flatten()(fc)\n",
    "fc = Dense(1024, activation='relu')(fc)\n",
    "fc = Dropout(0.5)(fc)\n",
    "predictions = Dense(1, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_test.npy')\n",
    "y_test = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_test.npy')\n",
    "\n",
    "model_list = ['D:/Projects/iSynPro/SyntheticPromoter/1DdenseNet/vanilla_CNN_weights/weights-29-0.52.hdf5',\n",
    "              'D:/Projects/iSynPro/SyntheticPromoter/1DdenseNet/separable_CNN_weights/weights-25-0.52.hdf5',\n",
    "              'D:/Projects/iSynPro/SyntheticPromoter/1DdenseNet/longstem_CNN_weights/weights-22-0.53.hdf5',\n",
    "             ]\n",
    "roc_list = []\n",
    "for path in model_list:\n",
    "    model = load_model(path)\n",
    "    y_pred = model.predict(x_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_list.append([fpr, tpr, auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnU3hi6WIjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27c02a42f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_list = ['Vanilla DenseNet',\n",
    "              'SeparableConvs DenseNet',\n",
    "              'Elongated Stem DenseNet']\n",
    "\n",
    "palette = sns.color_palette(\"cubehelix\", len(roc_list))\n",
    "\n",
    "#plot roc curve\n",
    "for i in range(len(roc_list)):\n",
    "    plt.plot(roc_list[i][0], \n",
    "             roc_list[i][1], \n",
    "             color=palette[i], \n",
    "             label='{0} (AUC = {1:.3f})'.format(label_list[i], roc_list[i][2]))\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for 1D DenseNet')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('d:/projects/isynpro/SyntheticPromoter/readme_figures/1ddense_roc.png', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
