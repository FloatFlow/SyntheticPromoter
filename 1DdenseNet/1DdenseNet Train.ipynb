{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D DenseNet CNN\n",
    "Similar to the architecture in this paper: https://arxiv.org/abs/1608.06993\n",
    "Adapted to a truncated, 1D version for our purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.layers import Conv2D, BatchNormalization, Dense, Dropout, Activation, AveragePooling1D, GaussianNoise\n",
    "from keras.layers import Input, Concatenate, Flatten, Conv1D, MaxPooling1D, Reshape, SeparableConv1D\n",
    "from keras.layers import GlobalMaxPooling1D, Lambda, GlobalAveragePooling1D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our data\n",
    "start_target_size = (672, 4)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_train.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 672, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNoise (None, 672, 4)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 336, 512)     14848       gaussian_noise_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 167, 512)     0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 167, 64)      32832       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 167, 64)      256         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 167, 64)      12352       batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 167, 64)      256         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 167, 64)      256         batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 167, 64)      4160        batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 167, 64)      256         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 167, 64)      12352       batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 167, 64)      256         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 167, 64)      256         batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 167, 128)     0           batch_normalization_53[0][0]     \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 167, 64)      8256        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 167, 64)      256         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 167, 64)      12352       batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 167, 64)      256         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 167, 64)      256         batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 167, 192)     0           batch_normalization_53[0][0]     \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 167, 64)      12352       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 167, 64)      256         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 167, 64)      12352       batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 167, 64)      256         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 167, 64)      256         batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 167, 256)     0           batch_normalization_53[0][0]     \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_59[0][0]     \n",
      "                                                                 batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 167, 64)      16448       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 167, 64)      256         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 167, 64)      12352       batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 167, 64)      256         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 167, 64)      256         batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 167, 320)     0           batch_normalization_53[0][0]     \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_59[0][0]     \n",
      "                                                                 batch_normalization_62[0][0]     \n",
      "                                                                 batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 167, 64)      20544       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 167, 64)      256         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 167, 64)      12352       batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 167, 64)      256         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 167, 64)      256         batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 167, 64)      4160        batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 83, 64)       0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 83, 64)       4160        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 83, 64)       256         conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 83, 64)       12352       batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 83, 64)       256         conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 83, 64)       256         batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 83, 64)       4160        batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 83, 64)       256         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 83, 64)       12352       batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 83, 64)       256         conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 83, 64)       256         batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 83, 128)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 83, 64)       8256        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 83, 64)       256         conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 83, 64)       12352       batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 83, 64)       256         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 83, 64)       256         batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 83, 192)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 83, 64)       12352       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 83, 64)       256         conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 83, 64)       12352       batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 83, 64)       256         conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 83, 64)       256         batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 83, 256)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 83, 64)       16448       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 83, 64)       256         conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 83, 64)       12352       batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 83, 64)       256         conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 83, 64)       256         batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 83, 320)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 83, 64)       20544       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 83, 64)       256         conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 83, 64)       12352       batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 83, 64)       256         conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 83, 64)       256         batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 83, 384)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 83, 64)       24640       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 83, 64)       256         conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 83, 64)       12352       batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 83, 64)       256         conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 83, 64)       256         batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 83, 448)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 83, 64)       28736       concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 83, 64)       256         conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 83, 64)       12352       batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 83, 64)       256         conv1d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 83, 64)       256         batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 83, 512)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 83, 64)       32832       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 83, 64)       256         conv1d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 83, 64)       12352       batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 83, 64)       256         conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 83, 64)       256         batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 83, 576)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 83, 64)       36928       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 83, 64)       256         conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 83, 64)       12352       batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 83, 64)       256         conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 83, 64)       256         batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 83, 640)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "                                                                 batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 83, 64)       41024       concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 83, 64)       256         conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 83, 64)       12352       batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 83, 64)       256         conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 83, 64)       256         batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 83, 704)      0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "                                                                 batch_normalization_98[0][0]     \n",
      "                                                                 batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 83, 64)       45120       concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 83, 64)       256         conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 83, 64)       12352       batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 83, 64)       256         conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 83, 64)       256         batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 83, 64)       4160        batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 5312)         0           conv1d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         5440512     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1025        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,070,657\n",
      "Trainable params: 6,063,745\n",
      "Non-trainable params: 6,912\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60291, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-01-0.60.hdf5\n",
      " - 103s - loss: 0.6707 - binary_accuracy: 0.6052 - val_loss: 0.6029 - val_binary_accuracy: 0.6419\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60291 to 0.56998, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-02-0.57.hdf5\n",
      " - 74s - loss: 0.5980 - binary_accuracy: 0.6691 - val_loss: 0.5700 - val_binary_accuracy: 0.7006\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56998 to 0.56154, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-03-0.56.hdf5\n",
      " - 73s - loss: 0.5779 - binary_accuracy: 0.6883 - val_loss: 0.5615 - val_binary_accuracy: 0.7054\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56154 to 0.55106, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-04-0.55.hdf5\n",
      " - 73s - loss: 0.5645 - binary_accuracy: 0.6958 - val_loss: 0.5511 - val_binary_accuracy: 0.7092\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55106 to 0.54524, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-05-0.55.hdf5\n",
      " - 73s - loss: 0.5577 - binary_accuracy: 0.7033 - val_loss: 0.5452 - val_binary_accuracy: 0.7162\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54524 to 0.53782, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-06-0.54.hdf5\n",
      " - 73s - loss: 0.5477 - binary_accuracy: 0.7110 - val_loss: 0.5378 - val_binary_accuracy: 0.7135\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 73s - loss: 0.5416 - binary_accuracy: 0.7153 - val_loss: 0.5398 - val_binary_accuracy: 0.7243\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 73s - loss: 0.5363 - binary_accuracy: 0.7222 - val_loss: 0.5380 - val_binary_accuracy: 0.7259\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.53782 to 0.53036, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-09-0.53.hdf5\n",
      " - 73s - loss: 0.5335 - binary_accuracy: 0.7267 - val_loss: 0.5304 - val_binary_accuracy: 0.7286\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 72s - loss: 0.5268 - binary_accuracy: 0.7267 - val_loss: 0.5307 - val_binary_accuracy: 0.7351\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 75s - loss: 0.5253 - binary_accuracy: 0.7302 - val_loss: 0.5343 - val_binary_accuracy: 0.7254\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 72s - loss: 0.5233 - binary_accuracy: 0.7322 - val_loss: 0.5400 - val_binary_accuracy: 0.7243\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 72s - loss: 0.5184 - binary_accuracy: 0.7352 - val_loss: 0.5390 - val_binary_accuracy: 0.7291\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.53036 to 0.52981, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-14-0.53.hdf5\n",
      " - 73s - loss: 0.5171 - binary_accuracy: 0.7377 - val_loss: 0.5298 - val_binary_accuracy: 0.7264\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 73s - loss: 0.5161 - binary_accuracy: 0.7371 - val_loss: 0.5306 - val_binary_accuracy: 0.7297\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.52981 to 0.52043, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-16-0.52.hdf5\n",
      " - 73s - loss: 0.5124 - binary_accuracy: 0.7379 - val_loss: 0.5204 - val_binary_accuracy: 0.7286\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 72s - loss: 0.5108 - binary_accuracy: 0.7414 - val_loss: 0.5208 - val_binary_accuracy: 0.7329\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 72s - loss: 0.5108 - binary_accuracy: 0.7399 - val_loss: 0.5326 - val_binary_accuracy: 0.7297\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.52043 to 0.51961, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-19-0.52.hdf5\n",
      " - 73s - loss: 0.5069 - binary_accuracy: 0.7422 - val_loss: 0.5196 - val_binary_accuracy: 0.7340\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 72s - loss: 0.5060 - binary_accuracy: 0.7437 - val_loss: 0.5247 - val_binary_accuracy: 0.7318\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 72s - loss: 0.5039 - binary_accuracy: 0.7464 - val_loss: 0.5250 - val_binary_accuracy: 0.7307\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 72s - loss: 0.5037 - binary_accuracy: 0.7462 - val_loss: 0.5225 - val_binary_accuracy: 0.7281\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 72s - loss: 0.5020 - binary_accuracy: 0.7440 - val_loss: 0.5267 - val_binary_accuracy: 0.7270\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 72s - loss: 0.4995 - binary_accuracy: 0.7471 - val_loss: 0.5202 - val_binary_accuracy: 0.7211\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 72s - loss: 0.4986 - binary_accuracy: 0.7485 - val_loss: 0.5210 - val_binary_accuracy: 0.7302\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 72s - loss: 0.4985 - binary_accuracy: 0.7492 - val_loss: 0.5279 - val_binary_accuracy: 0.7281\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 72s - loss: 0.4962 - binary_accuracy: 0.7491 - val_loss: 0.5310 - val_binary_accuracy: 0.7221\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 72s - loss: 0.4942 - binary_accuracy: 0.7495 - val_loss: 0.5271 - val_binary_accuracy: 0.7302\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.51961 to 0.51893, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-29-0.52.hdf5\n",
      " - 73s - loss: 0.4931 - binary_accuracy: 0.7522 - val_loss: 0.5189 - val_binary_accuracy: 0.7302\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 73s - loss: 0.4902 - binary_accuracy: 0.7502 - val_loss: 0.5269 - val_binary_accuracy: 0.7259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a8c1cf1518>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D Densenet\n",
    "\n",
    "#set of conv blocks wrapper\n",
    "def conv_block(x, dim):\n",
    "    x1 = Conv1D(dim, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Conv1D(dim, kernel_size=3, strides=1, padding='same', activation='relu')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    return x1\n",
    "\n",
    "# dense block wrapper\n",
    "def dense_block(inlayer, convs, dims):\n",
    "    conv_list = []\n",
    "    ministem = conv_block(inlayer, dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    ministem = conv_block(conv_list[0], dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    for _ in range(convs-2):\n",
    "        x = Concatenate()([layer for layer in conv_list])\n",
    "        x = conv_block(x, dims)\n",
    "        x = BatchNormalization()(x)\n",
    "        conv_list.append(x)\n",
    "    return conv_list[-1]\n",
    "\n",
    "## build our model\n",
    "# stem\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x = Conv1D(512, kernel_size=7, strides=2, padding='same', activation='relu')(x)\n",
    "x = MaxPooling1D(pool_size=3, strides=2)(x)\n",
    "    \n",
    "# dense block 1\n",
    "d1 = dense_block(x, 6, 64)\n",
    "\n",
    "#transition\n",
    "t = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d1)\n",
    "t = MaxPooling1D(pool_size=2, strides=2)(t)\n",
    "\n",
    "# dense block 2\n",
    "d2 = dense_block(t, 12, 64)\n",
    "\n",
    "# optional depth, doesn't seem to help\n",
    "'''\n",
    "#transition\n",
    "t2 = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "t2 = AveragePooling1D(pool_size=2, strides=2)(t2)\n",
    "\n",
    "# dense block 2\n",
    "d3 = dense_block(t2, 6, 64)\n",
    "'''\n",
    "\n",
    "# exit stem\n",
    "fc = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "fc = Flatten()(fc)\n",
    "fc = Dense(1024, activation='relu')(fc)\n",
    "fc = Dropout(0.5)(fc)\n",
    "predictions = Dense(1, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 672, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_5 (GaussianNoise (None, 672, 4)       0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 336, 512)     14848       gaussian_noise_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 167, 512)     0           conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_37 (SeparableC (None, 167, 64)      33344       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 167, 64)      256         separable_conv1d_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_38 (SeparableC (None, 167, 64)      4352        batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 167, 64)      256         separable_conv1d_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 167, 64)      256         batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_39 (SeparableC (None, 167, 64)      4224        batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 167, 64)      256         separable_conv1d_39[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_40 (SeparableC (None, 167, 64)      4352        batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 167, 64)      256         separable_conv1d_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 167, 64)      256         batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 167, 128)     0           batch_normalization_161[0][0]    \n",
      "                                                                 batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_41 (SeparableC (None, 167, 64)      8384        concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 167, 64)      256         separable_conv1d_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_42 (SeparableC (None, 167, 64)      4352        batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 167, 64)      256         separable_conv1d_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 167, 64)      256         batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 167, 192)     0           batch_normalization_161[0][0]    \n",
      "                                                                 batch_normalization_164[0][0]    \n",
      "                                                                 batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_43 (SeparableC (None, 167, 64)      12544       concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 167, 64)      256         separable_conv1d_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_44 (SeparableC (None, 167, 64)      4352        batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 167, 64)      256         separable_conv1d_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 167, 64)      256         batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 167, 256)     0           batch_normalization_161[0][0]    \n",
      "                                                                 batch_normalization_164[0][0]    \n",
      "                                                                 batch_normalization_167[0][0]    \n",
      "                                                                 batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_45 (SeparableC (None, 167, 64)      16704       concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 167, 64)      256         separable_conv1d_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_46 (SeparableC (None, 167, 64)      4352        batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 167, 64)      256         separable_conv1d_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 167, 64)      256         batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 167, 320)     0           batch_normalization_161[0][0]    \n",
      "                                                                 batch_normalization_164[0][0]    \n",
      "                                                                 batch_normalization_167[0][0]    \n",
      "                                                                 batch_normalization_170[0][0]    \n",
      "                                                                 batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_47 (SeparableC (None, 167, 64)      20864       concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 167, 64)      256         separable_conv1d_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_48 (SeparableC (None, 167, 64)      4352        batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 167, 64)      256         separable_conv1d_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 167, 64)      256         batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 167, 64)      4160        batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 83, 64)       0           conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_49 (SeparableC (None, 83, 64)       4224        max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 83, 64)       256         separable_conv1d_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_50 (SeparableC (None, 83, 64)       4352        batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 83, 64)       256         separable_conv1d_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 83, 64)       256         batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_51 (SeparableC (None, 83, 64)       4224        batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 83, 64)       256         separable_conv1d_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_52 (SeparableC (None, 83, 64)       4352        batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 83, 64)       256         separable_conv1d_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 83, 64)       256         batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 83, 128)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_53 (SeparableC (None, 83, 64)       8384        concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 83, 64)       256         separable_conv1d_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_54 (SeparableC (None, 83, 64)       4352        batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 83, 64)       256         separable_conv1d_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 83, 64)       256         batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 83, 192)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_55 (SeparableC (None, 83, 64)       12544       concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 83, 64)       256         separable_conv1d_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_56 (SeparableC (None, 83, 64)       4352        batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 83, 64)       256         separable_conv1d_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 83, 64)       256         batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 83, 256)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_57 (SeparableC (None, 83, 64)       16704       concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 83, 64)       256         separable_conv1d_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_58 (SeparableC (None, 83, 64)       4352        batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 83, 64)       256         separable_conv1d_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 83, 64)       256         batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 83, 320)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_59 (SeparableC (None, 83, 64)       20864       concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 83, 64)       256         separable_conv1d_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_60 (SeparableC (None, 83, 64)       4352        batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 83, 64)       256         separable_conv1d_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 83, 64)       256         batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 83, 384)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_61 (SeparableC (None, 83, 64)       25024       concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 83, 64)       256         separable_conv1d_61[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_62 (SeparableC (None, 83, 64)       4352        batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 83, 64)       256         separable_conv1d_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 83, 64)       256         batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 83, 448)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_63 (SeparableC (None, 83, 64)       29184       concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 83, 64)       256         separable_conv1d_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_64 (SeparableC (None, 83, 64)       4352        batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 83, 64)       256         separable_conv1d_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 83, 64)       256         batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 83, 512)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "                                                                 batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_65 (SeparableC (None, 83, 64)       33344       concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 83, 64)       256         separable_conv1d_65[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_66 (SeparableC (None, 83, 64)       4352        batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 83, 64)       256         separable_conv1d_66[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 83, 64)       256         batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 83, 576)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "                                                                 batch_normalization_200[0][0]    \n",
      "                                                                 batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_67 (SeparableC (None, 83, 64)       37504       concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 83, 64)       256         separable_conv1d_67[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_68 (SeparableC (None, 83, 64)       4352        batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 83, 64)       256         separable_conv1d_68[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 83, 64)       256         batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 83, 640)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "                                                                 batch_normalization_200[0][0]    \n",
      "                                                                 batch_normalization_203[0][0]    \n",
      "                                                                 batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_69 (SeparableC (None, 83, 64)       41664       concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 83, 64)       256         separable_conv1d_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_70 (SeparableC (None, 83, 64)       4352        batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 83, 64)       256         separable_conv1d_70[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 83, 64)       256         batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 83, 704)      0           batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_182[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_188[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "                                                                 batch_normalization_200[0][0]    \n",
      "                                                                 batch_normalization_203[0][0]    \n",
      "                                                                 batch_normalization_206[0][0]    \n",
      "                                                                 batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_71 (SeparableC (None, 83, 64)       45824       concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 83, 64)       256         separable_conv1d_71[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_72 (SeparableC (None, 83, 64)       4352        batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 83, 64)       256         separable_conv1d_72[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 83, 64)       256         batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 83, 64)       4160        batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 5312)         0           conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1024)         5440512     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,932,417\n",
      "Trainable params: 5,925,505\n",
      "Non-trainable params: 6,912\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63842, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-01-0.64.hdf5\n",
      " - 134s - loss: 0.7047 - binary_accuracy: 0.5651 - val_loss: 0.6384 - val_binary_accuracy: 0.6187\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63842 to 0.57821, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-02-0.58.hdf5\n",
      " - 83s - loss: 0.6164 - binary_accuracy: 0.6566 - val_loss: 0.5782 - val_binary_accuracy: 0.6834\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57821 to 0.57262, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-03-0.57.hdf5\n",
      " - 83s - loss: 0.5940 - binary_accuracy: 0.6791 - val_loss: 0.5726 - val_binary_accuracy: 0.6920\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57262 to 0.56834, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-04-0.57.hdf5\n",
      " - 83s - loss: 0.5809 - binary_accuracy: 0.6842 - val_loss: 0.5683 - val_binary_accuracy: 0.6979\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56834 to 0.56248, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-05-0.56.hdf5\n",
      " - 83s - loss: 0.5699 - binary_accuracy: 0.6967 - val_loss: 0.5625 - val_binary_accuracy: 0.6952\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 82s - loss: 0.5624 - binary_accuracy: 0.7036 - val_loss: 0.5728 - val_binary_accuracy: 0.7081\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.56248 to 0.55794, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-07-0.56.hdf5\n",
      " - 83s - loss: 0.5593 - binary_accuracy: 0.7063 - val_loss: 0.5579 - val_binary_accuracy: 0.7033\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55794 to 0.55688, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-08-0.56.hdf5\n",
      " - 83s - loss: 0.5518 - binary_accuracy: 0.7113 - val_loss: 0.5569 - val_binary_accuracy: 0.7017\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 82s - loss: 0.5487 - binary_accuracy: 0.7119 - val_loss: 0.5589 - val_binary_accuracy: 0.7076\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.55688 to 0.54655, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-10-0.55.hdf5\n",
      " - 83s - loss: 0.5426 - binary_accuracy: 0.7179 - val_loss: 0.5466 - val_binary_accuracy: 0.7173\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.54655 to 0.54075, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-11-0.54.hdf5\n",
      " - 83s - loss: 0.5367 - binary_accuracy: 0.7204 - val_loss: 0.5407 - val_binary_accuracy: 0.7216\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.54075 to 0.53277, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-12-0.53.hdf5\n",
      " - 83s - loss: 0.5339 - binary_accuracy: 0.7233 - val_loss: 0.5328 - val_binary_accuracy: 0.7216\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 82s - loss: 0.5300 - binary_accuracy: 0.7225 - val_loss: 0.5385 - val_binary_accuracy: 0.7135\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 82s - loss: 0.5286 - binary_accuracy: 0.7295 - val_loss: 0.5363 - val_binary_accuracy: 0.7221\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 82s - loss: 0.5239 - binary_accuracy: 0.7289 - val_loss: 0.5405 - val_binary_accuracy: 0.7254\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 83s - loss: 0.5208 - binary_accuracy: 0.7320 - val_loss: 0.5390 - val_binary_accuracy: 0.7216\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 83s - loss: 0.5198 - binary_accuracy: 0.7333 - val_loss: 0.5346 - val_binary_accuracy: 0.7270\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 83s - loss: 0.5161 - binary_accuracy: 0.7352 - val_loss: 0.5382 - val_binary_accuracy: 0.7248\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.53277 to 0.53222, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-19-0.53.hdf5\n",
      " - 84s - loss: 0.5158 - binary_accuracy: 0.7386 - val_loss: 0.5322 - val_binary_accuracy: 0.7248\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 83s - loss: 0.5143 - binary_accuracy: 0.7387 - val_loss: 0.5363 - val_binary_accuracy: 0.7216\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 83s - loss: 0.5094 - binary_accuracy: 0.7413 - val_loss: 0.5401 - val_binary_accuracy: 0.7205\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.53222 to 0.52935, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-22-0.53.hdf5\n",
      " - 84s - loss: 0.5091 - binary_accuracy: 0.7400 - val_loss: 0.5293 - val_binary_accuracy: 0.7232\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 83s - loss: 0.5052 - binary_accuracy: 0.7431 - val_loss: 0.5381 - val_binary_accuracy: 0.7221\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.52935 to 0.52665, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-24-0.53.hdf5\n",
      " - 83s - loss: 0.5039 - binary_accuracy: 0.7441 - val_loss: 0.5266 - val_binary_accuracy: 0.7178\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.52665 to 0.52223, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights\\weights-25-0.52.hdf5\n",
      " - 84s - loss: 0.5023 - binary_accuracy: 0.7425 - val_loss: 0.5222 - val_binary_accuracy: 0.7243\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 83s - loss: 0.5004 - binary_accuracy: 0.7469 - val_loss: 0.5262 - val_binary_accuracy: 0.7221\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 83s - loss: 0.4999 - binary_accuracy: 0.7474 - val_loss: 0.5237 - val_binary_accuracy: 0.7243\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 83s - loss: 0.4971 - binary_accuracy: 0.7454 - val_loss: 0.5307 - val_binary_accuracy: 0.7173\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 83s - loss: 0.4987 - binary_accuracy: 0.7455 - val_loss: 0.5357 - val_binary_accuracy: 0.7194\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 82s - loss: 0.4946 - binary_accuracy: 0.7479 - val_loss: 0.5273 - val_binary_accuracy: 0.7157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a8f1f50f28>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D Densenet, with separable depthwise 1D convs\n",
    "\n",
    "#set of conv blocks wrapper\n",
    "def conv_block(x, dim):\n",
    "    x1 = SeparableConv1D(dim, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = SeparableConv1D(dim, kernel_size=3, strides=1, padding='same', activation='relu')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    return x1\n",
    "\n",
    "# dense block wrapper\n",
    "def dense_block(inlayer, convs, dims):\n",
    "    conv_list = []\n",
    "    ministem = conv_block(inlayer, dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    ministem = conv_block(conv_list[0], dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    for _ in range(convs-2):\n",
    "        x = Concatenate()([layer for layer in conv_list])\n",
    "        x = conv_block(x, dims)\n",
    "        x = BatchNormalization()(x)\n",
    "        conv_list.append(x)\n",
    "    return conv_list[-1]\n",
    "\n",
    "## build our model\n",
    "# stem\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x = Conv1D(512, kernel_size=7, strides=2, padding='same', activation='relu')(x)\n",
    "x = MaxPooling1D(pool_size=3, strides=2)(x)\n",
    "    \n",
    "# dense block 1\n",
    "d1 = dense_block(x, 6, 64)\n",
    "\n",
    "#transition\n",
    "t = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d1)\n",
    "t = MaxPooling1D(pool_size=2, strides=2)(t)\n",
    "\n",
    "# dense block 2\n",
    "d2 = dense_block(t, 12, 64)\n",
    "\n",
    "# optional depth\n",
    "'''\n",
    "#transition\n",
    "t2 = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "t2 = AveragePooling1D(pool_size=2, strides=2)(t2)\n",
    "\n",
    "# dense block 2\n",
    "d3 = dense_block(t2, 6, 64)\n",
    "'''\n",
    "\n",
    "# exit stem\n",
    "fc = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "#fc = GlobalAveragePooling1D()(fc)\n",
    "fc = Flatten()(fc)\n",
    "fc = Dense(1024, activation='relu')(fc)\n",
    "fc = Dropout(0.5)(fc)\n",
    "predictions = Dense(1, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 672, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_7 (GaussianNoise (None, 672, 4)       0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)             (None, 672, 128)     640         gaussian_noise_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 672, 128)     512         conv1d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_123 (Conv1D)             (None, 672, 128)     49280       batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 672, 128)     512         conv1d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 672, 128)     512         batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_124 (Conv1D)             (None, 672, 128)     16512       batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 672, 128)     512         conv1d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_125 (Conv1D)             (None, 672, 128)     49280       batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 672, 128)     512         conv1d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 672, 128)     512         batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 672, 256)     0           batch_normalization_269[0][0]    \n",
      "                                                                 batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_126 (Conv1D)             (None, 672, 128)     32896       concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 672, 128)     512         conv1d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_127 (Conv1D)             (None, 672, 128)     49280       batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 672, 128)     512         conv1d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 672, 128)     512         batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 672, 384)     0           batch_normalization_269[0][0]    \n",
      "                                                                 batch_normalization_272[0][0]    \n",
      "                                                                 batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_128 (Conv1D)             (None, 672, 128)     49280       concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 672, 128)     512         conv1d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_129 (Conv1D)             (None, 672, 128)     49280       batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 672, 128)     512         conv1d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 672, 128)     512         batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 672, 512)     0           batch_normalization_269[0][0]    \n",
      "                                                                 batch_normalization_272[0][0]    \n",
      "                                                                 batch_normalization_275[0][0]    \n",
      "                                                                 batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_130 (Conv1D)             (None, 672, 128)     65664       concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 672, 128)     512         conv1d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_131 (Conv1D)             (None, 672, 128)     49280       batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 672, 128)     512         conv1d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 672, 128)     512         batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 672, 640)     0           batch_normalization_269[0][0]    \n",
      "                                                                 batch_normalization_272[0][0]    \n",
      "                                                                 batch_normalization_275[0][0]    \n",
      "                                                                 batch_normalization_278[0][0]    \n",
      "                                                                 batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_132 (Conv1D)             (None, 672, 128)     82048       concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 672, 128)     512         conv1d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_133 (Conv1D)             (None, 672, 128)     49280       batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 672, 128)     512         conv1d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 672, 128)     512         batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_134 (Conv1D)             (None, 672, 128)     16512       batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 336, 128)     0           conv1d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_135 (Conv1D)             (None, 336, 64)      8256        max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 336, 64)      256         conv1d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_136 (Conv1D)             (None, 336, 64)      12352       batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 336, 64)      256         conv1d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 336, 64)      256         batch_normalization_286[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv1d_137 (Conv1D)             (None, 336, 64)      4160        batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 336, 64)      256         conv1d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_138 (Conv1D)             (None, 336, 64)      12352       batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 336, 64)      256         conv1d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 336, 64)      256         batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 336, 128)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_139 (Conv1D)             (None, 336, 64)      8256        concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 336, 64)      256         conv1d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_140 (Conv1D)             (None, 336, 64)      12352       batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 336, 64)      256         conv1d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 336, 64)      256         batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 336, 192)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_141 (Conv1D)             (None, 336, 64)      12352       concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 336, 64)      256         conv1d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_142 (Conv1D)             (None, 336, 64)      12352       batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 336, 64)      256         conv1d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 336, 64)      256         batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 336, 256)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_143 (Conv1D)             (None, 336, 64)      16448       concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 336, 64)      256         conv1d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_144 (Conv1D)             (None, 336, 64)      12352       batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 336, 64)      256         conv1d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 336, 64)      256         batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 336, 320)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_145 (Conv1D)             (None, 336, 64)      20544       concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 336, 64)      256         conv1d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_146 (Conv1D)             (None, 336, 64)      12352       batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 336, 64)      256         conv1d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 336, 64)      256         batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 336, 384)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_147 (Conv1D)             (None, 336, 64)      24640       concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 336, 64)      256         conv1d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_148 (Conv1D)             (None, 336, 64)      12352       batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 336, 64)      256         conv1d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 336, 64)      256         batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 336, 448)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "                                                                 batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_149 (Conv1D)             (None, 336, 64)      28736       concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 336, 64)      256         conv1d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_150 (Conv1D)             (None, 336, 64)      12352       batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 336, 64)      256         conv1d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 336, 64)      256         batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 336, 512)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "                                                                 batch_normalization_305[0][0]    \n",
      "                                                                 batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_151 (Conv1D)             (None, 336, 64)      32832       concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 336, 64)      256         conv1d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_152 (Conv1D)             (None, 336, 64)      12352       batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 336, 64)      256         conv1d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 336, 64)      256         batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 336, 576)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "                                                                 batch_normalization_305[0][0]    \n",
      "                                                                 batch_normalization_308[0][0]    \n",
      "                                                                 batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_153 (Conv1D)             (None, 336, 64)      36928       concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 336, 64)      256         conv1d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_154 (Conv1D)             (None, 336, 64)      12352       batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 336, 64)      256         conv1d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 336, 64)      256         batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 336, 640)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "                                                                 batch_normalization_305[0][0]    \n",
      "                                                                 batch_normalization_308[0][0]    \n",
      "                                                                 batch_normalization_311[0][0]    \n",
      "                                                                 batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_155 (Conv1D)             (None, 336, 64)      41024       concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 336, 64)      256         conv1d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_156 (Conv1D)             (None, 336, 64)      12352       batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 336, 64)      256         conv1d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 336, 64)      256         batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 336, 704)     0           batch_normalization_287[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_293[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_299[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "                                                                 batch_normalization_305[0][0]    \n",
      "                                                                 batch_normalization_308[0][0]    \n",
      "                                                                 batch_normalization_311[0][0]    \n",
      "                                                                 batch_normalization_314[0][0]    \n",
      "                                                                 batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_157 (Conv1D)             (None, 336, 64)      45120       concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 336, 64)      256         conv1d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_158 (Conv1D)             (None, 336, 64)      12352       batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 336, 64)      256         conv1d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 336, 64)      256         batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_159 (Conv1D)             (None, 336, 64)      4160        batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 168, 64)      0           conv1d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 10752)        0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         11011072    flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            1025        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,021,441\n",
      "Trainable params: 12,012,225\n",
      "Non-trainable params: 9,216\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59764, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-01-0.60.hdf5\n",
      " - 207s - loss: 0.6841 - binary_accuracy: 0.6059 - val_loss: 0.5976 - val_binary_accuracy: 0.6731\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59764 to 0.58804, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-02-0.59.hdf5\n",
      " - 144s - loss: 0.5866 - binary_accuracy: 0.6856 - val_loss: 0.5880 - val_binary_accuracy: 0.6974\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 144s - loss: 0.5672 - binary_accuracy: 0.6981 - val_loss: 0.5929 - val_binary_accuracy: 0.7151\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58804 to 0.57400, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-04-0.57.hdf5\n",
      " - 144s - loss: 0.5575 - binary_accuracy: 0.7064 - val_loss: 0.5740 - val_binary_accuracy: 0.7071\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.57400 to 0.56851, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-05-0.57.hdf5\n",
      " - 145s - loss: 0.5471 - binary_accuracy: 0.7216 - val_loss: 0.5685 - val_binary_accuracy: 0.7173\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56851 to 0.56592, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-06-0.57.hdf5\n",
      " - 145s - loss: 0.5433 - binary_accuracy: 0.7204 - val_loss: 0.5659 - val_binary_accuracy: 0.7151\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.56592 to 0.54141, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-07-0.54.hdf5\n",
      " - 145s - loss: 0.5383 - binary_accuracy: 0.7213 - val_loss: 0.5414 - val_binary_accuracy: 0.7114\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 144s - loss: 0.5326 - binary_accuracy: 0.7292 - val_loss: 0.5468 - val_binary_accuracy: 0.7173\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 144s - loss: 0.5306 - binary_accuracy: 0.7268 - val_loss: 0.5541 - val_binary_accuracy: 0.7216\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.54141 to 0.53692, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-10-0.54.hdf5\n",
      " - 145s - loss: 0.5206 - binary_accuracy: 0.7356 - val_loss: 0.5369 - val_binary_accuracy: 0.7329\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 143s - loss: 0.5141 - binary_accuracy: 0.7380 - val_loss: 0.5528 - val_binary_accuracy: 0.7313\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 143s - loss: 0.5128 - binary_accuracy: 0.7395 - val_loss: 0.5583 - val_binary_accuracy: 0.7205\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.53692 to 0.53221, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-13-0.53.hdf5\n",
      " - 144s - loss: 0.5110 - binary_accuracy: 0.7409 - val_loss: 0.5322 - val_binary_accuracy: 0.7351\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 144s - loss: 0.5070 - binary_accuracy: 0.7456 - val_loss: 0.5357 - val_binary_accuracy: 0.7297\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 143s - loss: 0.5025 - binary_accuracy: 0.7463 - val_loss: 0.5498 - val_binary_accuracy: 0.7318\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 143s - loss: 0.5022 - binary_accuracy: 0.7446 - val_loss: 0.5505 - val_binary_accuracy: 0.7313\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 143s - loss: 0.5013 - binary_accuracy: 0.7480 - val_loss: 0.5360 - val_binary_accuracy: 0.7307\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 144s - loss: 0.4994 - binary_accuracy: 0.7475 - val_loss: 0.5360 - val_binary_accuracy: 0.7318\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 144s - loss: 0.4982 - binary_accuracy: 0.7502 - val_loss: 0.5332 - val_binary_accuracy: 0.7291\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 144s - loss: 0.4923 - binary_accuracy: 0.7526 - val_loss: 0.5356 - val_binary_accuracy: 0.7361\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.53221 to 0.53062, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-21-0.53.hdf5\n",
      " - 145s - loss: 0.4905 - binary_accuracy: 0.7526 - val_loss: 0.5306 - val_binary_accuracy: 0.7313\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.53062 to 0.52804, saving model to D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights\\weights-22-0.53.hdf5\n",
      " - 144s - loss: 0.4923 - binary_accuracy: 0.7526 - val_loss: 0.5280 - val_binary_accuracy: 0.7291\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 144s - loss: 0.4892 - binary_accuracy: 0.7553 - val_loss: 0.5345 - val_binary_accuracy: 0.7324\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 147s - loss: 0.4878 - binary_accuracy: 0.7541 - val_loss: 0.5308 - val_binary_accuracy: 0.7281\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 145s - loss: 0.4869 - binary_accuracy: 0.7575 - val_loss: 0.5471 - val_binary_accuracy: 0.7232\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 144s - loss: 0.4825 - binary_accuracy: 0.7590 - val_loss: 0.5336 - val_binary_accuracy: 0.7302\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 146s - loss: 0.4803 - binary_accuracy: 0.7602 - val_loss: 0.5435 - val_binary_accuracy: 0.7361\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 147s - loss: 0.4799 - binary_accuracy: 0.7578 - val_loss: 0.5387 - val_binary_accuracy: 0.7307\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 145s - loss: 0.4794 - binary_accuracy: 0.7617 - val_loss: 0.5322 - val_binary_accuracy: 0.7286\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 144s - loss: 0.4773 - binary_accuracy: 0.7628 - val_loss: 0.5385 - val_binary_accuracy: 0.7297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a932ff2ba8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D Densenet with elongated beginning stem\n",
    "\n",
    "#set of conv blocks wrapper\n",
    "def conv_block(x, dim):\n",
    "    x1 = Conv1D(dim, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Conv1D(dim, kernel_size=3, strides=1, padding='same', activation='relu')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    return x1\n",
    "\n",
    "# dense block wrapper\n",
    "def dense_block(inlayer, convs, dims):\n",
    "    conv_list = []\n",
    "    ministem = conv_block(inlayer, dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    ministem = conv_block(conv_list[0], dims)\n",
    "    ministem = BatchNormalization()(ministem)\n",
    "    conv_list.append(ministem)\n",
    "    for _ in range(convs-2):\n",
    "        x = Concatenate()([layer for layer in conv_list])\n",
    "        x = conv_block(x, dims)\n",
    "        x = BatchNormalization()(x)\n",
    "        conv_list.append(x)\n",
    "    return conv_list[-1]\n",
    "\n",
    "## build our model\n",
    "# stem\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "#x = Conv1D(512, kernel_size=7, strides=2, padding='same', activation='relu')(x)\n",
    "    \n",
    "# dense block 1\n",
    "d1 = dense_block(x, 6, 128)\n",
    "\n",
    "#transition\n",
    "t = Conv1D(128, kernel_size=1, strides=1, padding='same', activation='relu')(d1)\n",
    "t = MaxPooling1D(pool_size=2, strides=2)(t)\n",
    "\n",
    "# dense block 2\n",
    "d2 = dense_block(t, 12, 64)\n",
    "\n",
    "# optional depth\n",
    "'''\n",
    "#transition\n",
    "t2 = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "t2 = AveragePooling1D(pool_size=2, strides=2)(t2)\n",
    "\n",
    "# dense block 2\n",
    "d3 = dense_block(t2, 6, 64)\n",
    "'''\n",
    "\n",
    "# exit stem\n",
    "fc = Conv1D(64, kernel_size=1, strides=1, padding='same', activation='relu')(d2)\n",
    "fc = MaxPooling1D(pool_size=2, strides=2)(fc)\n",
    "fc = Flatten()(fc)\n",
    "fc = Dense(1024, activation='relu')(fc)\n",
    "fc = Dropout(0.5)(fc)\n",
    "predictions = Dense(1, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_test.npy')\n",
    "y_test = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_test.npy')\n",
    "\n",
    "model_list = ['D:/Projects/Github/SyntheticPromoter/1DdenseNet/vanilla_CNN_weights/weights-29-0.52.hdf5',\n",
    "              'D:/Projects/Github/SyntheticPromoter/1DdenseNet/separable_CNN_weights/weights-25-0.52.hdf5',\n",
    "              'D:/Projects/Github/SyntheticPromoter/1DdenseNet/longstem_CNN_weights/weights-22-0.53.hdf5',\n",
    "             ]\n",
    "roc_list = []\n",
    "for path in model_list:\n",
    "    model = load_model(path)\n",
    "    y_pred = model.predict(x_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_list.append([fpr, tpr, auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aa07643ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot roc curve\n",
    "plt.plot(roc_list[0][0], roc_list[0][1], color='darkorange', label='Vanilla DenseNet (AUC = %0.2f)' % roc_list[0][2])\n",
    "plt.plot(roc_list[1][0], roc_list[1][1], color='darkblue', label='SeparableConvs DenseNet (AUC = %0.2f)' % roc_list[1][2])\n",
    "plt.plot(roc_list[2][0], roc_list[2][1], color='darkgreen', label='Elongated Stem DenseNet (AUC = %0.2f)' % roc_list[2][2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('c:/users/wolf/desktop/SynPro/roc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
