{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DanQ CNN-LSTM Experiments\n",
    "Based on the DanQ neural network for DNA classification (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4914104/), these are a series of experiments designed to test what is the optimum architecture for our given problem of DNA promoter classification given limited data, while still remaining relatively true to the general concept of the DanQ CNN-LSTM. Parameters we examine are stride of pooling, convolution kernel size, type of convolution used, and number of convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from keras.layers import Conv2D, BatchNormalization, AveragePooling2D, Dense, Dropout, Activation, AveragePooling1D, Bidirectional, MaxPooling2D, GaussianNoise\n",
    "from keras.layers import Input, Concatenate, Flatten, Embedding, CuDNNLSTM, Conv1D, MaxPooling1D, LSTM, StackedRNNCells, LSTMCell, Reshape, TimeDistributed, SeparableConv1D\n",
    "from keras.layers import RepeatVector, Permute, merge, multiply, GlobalMaxPooling1D, Lambda, BatchNormalization, GlobalAveragePooling1D\n",
    "from keras.layers.merge import Multiply\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our data\n",
    "start_target_size = (672, 4)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68549, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-01-0.69.hdf5\n",
      " - 44s - loss: 0.6872 - binary_accuracy: 0.5452 - val_loss: 0.6855 - val_binary_accuracy: 0.5477\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68549 to 0.63686, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-02-0.64.hdf5\n",
      " - 42s - loss: 0.6606 - binary_accuracy: 0.6047 - val_loss: 0.6369 - val_binary_accuracy: 0.6440\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63686 to 0.58992, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-03-0.59.hdf5\n",
      " - 41s - loss: 0.6146 - binary_accuracy: 0.6612 - val_loss: 0.5899 - val_binary_accuracy: 0.6807\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58992 to 0.58494, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-04-0.58.hdf5\n",
      " - 41s - loss: 0.5913 - binary_accuracy: 0.6838 - val_loss: 0.5849 - val_binary_accuracy: 0.6914\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.58494 to 0.56397, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-05-0.56.hdf5\n",
      " - 41s - loss: 0.5785 - binary_accuracy: 0.6943 - val_loss: 0.5640 - val_binary_accuracy: 0.7108\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56397 to 0.56142, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-06-0.56.hdf5\n",
      " - 41s - loss: 0.5671 - binary_accuracy: 0.7051 - val_loss: 0.5614 - val_binary_accuracy: 0.7044\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.56142 to 0.55452, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-07-0.55.hdf5\n",
      " - 42s - loss: 0.5633 - binary_accuracy: 0.7037 - val_loss: 0.5545 - val_binary_accuracy: 0.7092\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 38s - loss: 0.5584 - binary_accuracy: 0.7084 - val_loss: 0.5580 - val_binary_accuracy: 0.7076\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.55452 to 0.54875, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-09-0.55.hdf5\n",
      " - 41s - loss: 0.5553 - binary_accuracy: 0.7089 - val_loss: 0.5487 - val_binary_accuracy: 0.7194\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.54875 to 0.54783, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-10-0.55.hdf5\n",
      " - 42s - loss: 0.5504 - binary_accuracy: 0.7192 - val_loss: 0.5478 - val_binary_accuracy: 0.7189\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 38s - loss: 0.5476 - binary_accuracy: 0.7140 - val_loss: 0.5489 - val_binary_accuracy: 0.7173\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 38s - loss: 0.5461 - binary_accuracy: 0.7165 - val_loss: 0.5488 - val_binary_accuracy: 0.7205\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 38s - loss: 0.5448 - binary_accuracy: 0.7170 - val_loss: 0.5488 - val_binary_accuracy: 0.7076\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.54783 to 0.53804, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-14-0.54.hdf5\n",
      " - 42s - loss: 0.5408 - binary_accuracy: 0.7203 - val_loss: 0.5380 - val_binary_accuracy: 0.7281\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 38s - loss: 0.5403 - binary_accuracy: 0.7194 - val_loss: 0.5397 - val_binary_accuracy: 0.7254\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 38s - loss: 0.5387 - binary_accuracy: 0.7178 - val_loss: 0.5432 - val_binary_accuracy: 0.7291\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 38s - loss: 0.5353 - binary_accuracy: 0.7203 - val_loss: 0.5458 - val_binary_accuracy: 0.7340\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.53804 to 0.53677, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-18-0.54.hdf5\n",
      " - 41s - loss: 0.5354 - binary_accuracy: 0.7228 - val_loss: 0.5368 - val_binary_accuracy: 0.7254\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.53677 to 0.53652, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-19-0.54.hdf5\n",
      " - 42s - loss: 0.5345 - binary_accuracy: 0.7235 - val_loss: 0.5365 - val_binary_accuracy: 0.7356\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 38s - loss: 0.5336 - binary_accuracy: 0.7276 - val_loss: 0.5375 - val_binary_accuracy: 0.7130\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.53652 to 0.52983, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-21-0.53.hdf5\n",
      " - 41s - loss: 0.5297 - binary_accuracy: 0.7251 - val_loss: 0.5298 - val_binary_accuracy: 0.7291\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 38s - loss: 0.5304 - binary_accuracy: 0.7261 - val_loss: 0.5396 - val_binary_accuracy: 0.7318\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 38s - loss: 0.5286 - binary_accuracy: 0.7252 - val_loss: 0.5309 - val_binary_accuracy: 0.7324\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.52983 to 0.52948, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-24-0.53.hdf5\n",
      " - 41s - loss: 0.5284 - binary_accuracy: 0.7249 - val_loss: 0.5295 - val_binary_accuracy: 0.7367\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 38s - loss: 0.5269 - binary_accuracy: 0.7263 - val_loss: 0.5343 - val_binary_accuracy: 0.7302\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.52948 to 0.52651, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-26-0.53.hdf5\n",
      " - 44s - loss: 0.5264 - binary_accuracy: 0.7276 - val_loss: 0.5265 - val_binary_accuracy: 0.7383\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.52651 to 0.52429, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-27-0.52.hdf5\n",
      " - 48s - loss: 0.5253 - binary_accuracy: 0.7283 - val_loss: 0.5243 - val_binary_accuracy: 0.7340\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.52429 to 0.52133, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights\\weights-28-0.52.hdf5\n",
      " - 54s - loss: 0.5215 - binary_accuracy: 0.7328 - val_loss: 0.5213 - val_binary_accuracy: 0.7421\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 54s - loss: 0.5203 - binary_accuracy: 0.7330 - val_loss: 0.5284 - val_binary_accuracy: 0.7259\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 54s - loss: 0.5212 - binary_accuracy: 0.7285 - val_loss: 0.5259 - val_binary_accuracy: 0.7270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x280fb2f8ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic 1D Conv CNN LSTM\n",
    "# ala DanQ\n",
    "# this is our base case\n",
    "\n",
    "# build our model\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x = Conv1D(512, kernel_size=26, strides=1, padding='same', activation='relu')(x)\n",
    "x = MaxPooling1D(pool_size=13, strides=13)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Bidirectional(CuDNNLSTM(256, return_sequences=True))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/danq_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes about kernel size and pool size\n",
    "It doesn't necessarily make sense to be using such large kernel and pool sizes. Most transcription factors bind to DNA sites that are between 8 and 16 nucleotides long. Even these sites tend to have smaller pockets within them where the transcription factor actually binds with a high affinity. At the risk of having more parameters, we can test whether a finer grained architecture helps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68160, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-01-0.68.hdf5\n",
      " - 72s - loss: 0.6905 - binary_accuracy: 0.5307 - val_loss: 0.6816 - val_binary_accuracy: 0.5530\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68160 to 0.65363, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-02-0.65.hdf5\n",
      " - 75s - loss: 0.6713 - binary_accuracy: 0.5900 - val_loss: 0.6536 - val_binary_accuracy: 0.6204\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65363 to 0.61188, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-03-0.61.hdf5\n",
      " - 73s - loss: 0.6336 - binary_accuracy: 0.6414 - val_loss: 0.6119 - val_binary_accuracy: 0.6699\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61188 to 0.59965, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-04-0.60.hdf5\n",
      " - 71s - loss: 0.6040 - binary_accuracy: 0.6703 - val_loss: 0.5997 - val_binary_accuracy: 0.6747\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.59965 to 0.57953, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-05-0.58.hdf5\n",
      " - 73s - loss: 0.5858 - binary_accuracy: 0.6861 - val_loss: 0.5795 - val_binary_accuracy: 0.6995\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.57953 to 0.56493, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-06-0.56.hdf5\n",
      " - 72s - loss: 0.5737 - binary_accuracy: 0.6975 - val_loss: 0.5649 - val_binary_accuracy: 0.7054\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 66s - loss: 0.5688 - binary_accuracy: 0.6997 - val_loss: 0.5683 - val_binary_accuracy: 0.7087\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 52s - loss: 0.5612 - binary_accuracy: 0.7065 - val_loss: 0.5657 - val_binary_accuracy: 0.6893\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.56493 to 0.55580, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-09-0.56.hdf5\n",
      " - 67s - loss: 0.5607 - binary_accuracy: 0.7053 - val_loss: 0.5558 - val_binary_accuracy: 0.7108\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.55580 to 0.54757, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-10-0.55.hdf5\n",
      " - 71s - loss: 0.5546 - binary_accuracy: 0.7122 - val_loss: 0.5476 - val_binary_accuracy: 0.7124\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 58s - loss: 0.5496 - binary_accuracy: 0.7141 - val_loss: 0.5816 - val_binary_accuracy: 0.6914\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.54757 to 0.54612, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-12-0.55.hdf5\n",
      " - 203s - loss: 0.5479 - binary_accuracy: 0.7178 - val_loss: 0.5461 - val_binary_accuracy: 0.7146\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.54612 to 0.54281, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-13-0.54.hdf5\n",
      " - 83s - loss: 0.5422 - binary_accuracy: 0.7205 - val_loss: 0.5428 - val_binary_accuracy: 0.7097\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.54281 to 0.53888, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-14-0.54.hdf5\n",
      " - 60s - loss: 0.5407 - binary_accuracy: 0.7209 - val_loss: 0.5389 - val_binary_accuracy: 0.7259\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.53888 to 0.53811, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-15-0.54.hdf5\n",
      " - 59s - loss: 0.5385 - binary_accuracy: 0.7230 - val_loss: 0.5381 - val_binary_accuracy: 0.7211\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.53811 to 0.53554, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-16-0.54.hdf5\n",
      " - 55s - loss: 0.5371 - binary_accuracy: 0.7227 - val_loss: 0.5355 - val_binary_accuracy: 0.7291\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.53554 to 0.53407, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-17-0.53.hdf5\n",
      " - 55s - loss: 0.5332 - binary_accuracy: 0.7268 - val_loss: 0.5341 - val_binary_accuracy: 0.7221\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 51s - loss: 0.5317 - binary_accuracy: 0.7249 - val_loss: 0.5355 - val_binary_accuracy: 0.7259\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.53407 to 0.53071, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-19-0.53.hdf5\n",
      " - 56s - loss: 0.5316 - binary_accuracy: 0.7246 - val_loss: 0.5307 - val_binary_accuracy: 0.7275\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.53071 to 0.52711, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-20-0.53.hdf5\n",
      " - 55s - loss: 0.5279 - binary_accuracy: 0.7293 - val_loss: 0.5271 - val_binary_accuracy: 0.7329\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 51s - loss: 0.5251 - binary_accuracy: 0.7311 - val_loss: 0.5328 - val_binary_accuracy: 0.7259\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.52711 to 0.52490, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-22-0.52.hdf5\n",
      " - 55s - loss: 0.5258 - binary_accuracy: 0.7291 - val_loss: 0.5249 - val_binary_accuracy: 0.7345\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 51s - loss: 0.5242 - binary_accuracy: 0.7297 - val_loss: 0.5252 - val_binary_accuracy: 0.7286\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 51s - loss: 0.5196 - binary_accuracy: 0.7350 - val_loss: 0.5269 - val_binary_accuracy: 0.7302\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 51s - loss: 0.5207 - binary_accuracy: 0.7333 - val_loss: 0.5261 - val_binary_accuracy: 0.7297\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 51s - loss: 0.5193 - binary_accuracy: 0.7328 - val_loss: 0.5274 - val_binary_accuracy: 0.7297\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 51s - loss: 0.5176 - binary_accuracy: 0.7345 - val_loss: 0.5262 - val_binary_accuracy: 0.7264\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 51s - loss: 0.5190 - binary_accuracy: 0.7345 - val_loss: 0.5280 - val_binary_accuracy: 0.7302\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.52490 to 0.52465, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights\\weights-29-0.52.hdf5\n",
      " - 55s - loss: 0.5151 - binary_accuracy: 0.7361 - val_loss: 0.5247 - val_binary_accuracy: 0.7297\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 51s - loss: 0.5151 - binary_accuracy: 0.7381 - val_loss: 0.5325 - val_binary_accuracy: 0.7329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x280f6135240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to DanQ as above\n",
    "# but with different pool and kernel sizes\n",
    "# and dropout schema\n",
    "\n",
    "# build our model\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x = Conv1D(256, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x = MaxPooling1D(pool_size=8, strides=8)(x)\n",
    "x = Bidirectional(CuDNNLSTM(256, return_sequences=True))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62570, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-01-0.63.hdf5\n",
      " - 186s - loss: 0.6705 - binary_accuracy: 0.5849 - val_loss: 0.6257 - val_binary_accuracy: 0.6268\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.62570 to 0.58325, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-02-0.58.hdf5\n",
      " - 181s - loss: 0.5982 - binary_accuracy: 0.6714 - val_loss: 0.5833 - val_binary_accuracy: 0.6909\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58325 to 0.56045, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-03-0.56.hdf5\n",
      " - 181s - loss: 0.5714 - binary_accuracy: 0.6962 - val_loss: 0.5605 - val_binary_accuracy: 0.7065\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56045 to 0.55899, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-04-0.56.hdf5\n",
      " - 181s - loss: 0.5594 - binary_accuracy: 0.7043 - val_loss: 0.5590 - val_binary_accuracy: 0.6909\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55899 to 0.55351, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-05-0.55.hdf5\n",
      " - 182s - loss: 0.5500 - binary_accuracy: 0.7126 - val_loss: 0.5535 - val_binary_accuracy: 0.7038\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.55351 to 0.54184, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-06-0.54.hdf5\n",
      " - 182s - loss: 0.5431 - binary_accuracy: 0.7170 - val_loss: 0.5418 - val_binary_accuracy: 0.7221\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 163s - loss: 0.5364 - binary_accuracy: 0.7228 - val_loss: 0.5443 - val_binary_accuracy: 0.7022\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.54184 to 0.53477, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-08-0.53.hdf5\n",
      " - 182s - loss: 0.5301 - binary_accuracy: 0.7270 - val_loss: 0.5348 - val_binary_accuracy: 0.7211\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.53477 to 0.53355, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-09-0.53.hdf5\n",
      " - 182s - loss: 0.5288 - binary_accuracy: 0.7286 - val_loss: 0.5336 - val_binary_accuracy: 0.7243\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.53355 to 0.52919, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-10-0.53.hdf5\n",
      " - 182s - loss: 0.5232 - binary_accuracy: 0.7313 - val_loss: 0.5292 - val_binary_accuracy: 0.7211\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.52919 to 0.52689, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-11-0.53.hdf5\n",
      " - 181s - loss: 0.5203 - binary_accuracy: 0.7334 - val_loss: 0.5269 - val_binary_accuracy: 0.7259\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.52689 to 0.52687, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-12-0.53.hdf5\n",
      " - 181s - loss: 0.5159 - binary_accuracy: 0.7352 - val_loss: 0.5269 - val_binary_accuracy: 0.7302\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 162s - loss: 0.5160 - binary_accuracy: 0.7399 - val_loss: 0.5284 - val_binary_accuracy: 0.7211\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.52687 to 0.52468, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-14-0.52.hdf5\n",
      " - 181s - loss: 0.5143 - binary_accuracy: 0.7377 - val_loss: 0.5247 - val_binary_accuracy: 0.7324\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.52468 to 0.52355, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-15-0.52.hdf5\n",
      " - 181s - loss: 0.5108 - binary_accuracy: 0.7404 - val_loss: 0.5235 - val_binary_accuracy: 0.7264\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.52355 to 0.51569, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-16-0.52.hdf5\n",
      " - 181s - loss: 0.5080 - binary_accuracy: 0.7408 - val_loss: 0.5157 - val_binary_accuracy: 0.7302\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 163s - loss: 0.5091 - binary_accuracy: 0.7413 - val_loss: 0.5254 - val_binary_accuracy: 0.7372\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 164s - loss: 0.5042 - binary_accuracy: 0.7423 - val_loss: 0.5159 - val_binary_accuracy: 0.7351\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 165s - loss: 0.5044 - binary_accuracy: 0.7440 - val_loss: 0.5194 - val_binary_accuracy: 0.7302\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 163s - loss: 0.5016 - binary_accuracy: 0.7452 - val_loss: 0.5220 - val_binary_accuracy: 0.7334\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 164s - loss: 0.5000 - binary_accuracy: 0.7462 - val_loss: 0.5192 - val_binary_accuracy: 0.7340\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.51569 to 0.51257, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-22-0.51.hdf5\n",
      " - 182s - loss: 0.5005 - binary_accuracy: 0.7465 - val_loss: 0.5126 - val_binary_accuracy: 0.7361\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.51257 to 0.51111, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-23-0.51.hdf5\n",
      " - 183s - loss: 0.4984 - binary_accuracy: 0.7461 - val_loss: 0.5111 - val_binary_accuracy: 0.7356\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 163s - loss: 0.4960 - binary_accuracy: 0.7489 - val_loss: 0.5136 - val_binary_accuracy: 0.7356\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.51111 to 0.51034, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-25-0.51.hdf5\n",
      " - 182s - loss: 0.4950 - binary_accuracy: 0.7492 - val_loss: 0.5103 - val_binary_accuracy: 0.7356\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 163s - loss: 0.4932 - binary_accuracy: 0.7496 - val_loss: 0.5198 - val_binary_accuracy: 0.7361\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 165s - loss: 0.4923 - binary_accuracy: 0.7487 - val_loss: 0.5162 - val_binary_accuracy: 0.7404\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 167s - loss: 0.4909 - binary_accuracy: 0.7534 - val_loss: 0.5141 - val_binary_accuracy: 0.7361\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 164s - loss: 0.4896 - binary_accuracy: 0.7521 - val_loss: 0.5157 - val_binary_accuracy: 0.7324\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.51034 to 0.50799, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights\\weights-30-0.51.hdf5\n",
      " - 184s - loss: 0.4914 - binary_accuracy: 0.7510 - val_loss: 0.5080 - val_binary_accuracy: 0.7388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b7511ba58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to DanQ as above\n",
    "# but with different pool and kernel sizes\n",
    "# and dropout schema\n",
    "\n",
    "# build our model\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x = Conv1D(256, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x = MaxPooling1D(pool_size=8, strides=2)(x)\n",
    "x = Bidirectional(CuDNNLSTM(256, return_sequences=True))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65961, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-01-0.66.hdf5\n",
      " - 97s - loss: 0.6869 - binary_accuracy: 0.5441 - val_loss: 0.6596 - val_binary_accuracy: 0.6451\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65961 to 0.58407, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-02-0.58.hdf5\n",
      " - 97s - loss: 0.6228 - binary_accuracy: 0.6533 - val_loss: 0.5841 - val_binary_accuracy: 0.6780\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58407 to 0.58076, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-03-0.58.hdf5\n",
      " - 96s - loss: 0.5815 - binary_accuracy: 0.6854 - val_loss: 0.5808 - val_binary_accuracy: 0.6866\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58076 to 0.55485, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-04-0.55.hdf5\n",
      " - 97s - loss: 0.5674 - binary_accuracy: 0.6999 - val_loss: 0.5548 - val_binary_accuracy: 0.7092\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55485 to 0.54961, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-05-0.55.hdf5\n",
      " - 96s - loss: 0.5545 - binary_accuracy: 0.7103 - val_loss: 0.5496 - val_binary_accuracy: 0.7151\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54961 to 0.54419, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-06-0.54.hdf5\n",
      " - 96s - loss: 0.5449 - binary_accuracy: 0.7176 - val_loss: 0.5442 - val_binary_accuracy: 0.7189\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.54419 to 0.53638, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-07-0.54.hdf5\n",
      " - 95s - loss: 0.5372 - binary_accuracy: 0.7232 - val_loss: 0.5364 - val_binary_accuracy: 0.7221\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 91s - loss: 0.5298 - binary_accuracy: 0.7288 - val_loss: 0.5380 - val_binary_accuracy: 0.7270\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.53638 to 0.52863, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-09-0.53.hdf5\n",
      " - 97s - loss: 0.5252 - binary_accuracy: 0.7323 - val_loss: 0.5286 - val_binary_accuracy: 0.7248\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.52863 to 0.52538, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-10-0.53.hdf5\n",
      " - 97s - loss: 0.5236 - binary_accuracy: 0.7358 - val_loss: 0.5254 - val_binary_accuracy: 0.7340\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.52538 to 0.52209, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-11-0.52.hdf5\n",
      " - 95s - loss: 0.5193 - binary_accuracy: 0.7370 - val_loss: 0.5221 - val_binary_accuracy: 0.7259\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 91s - loss: 0.5158 - binary_accuracy: 0.7403 - val_loss: 0.5234 - val_binary_accuracy: 0.7318\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 91s - loss: 0.5128 - binary_accuracy: 0.7408 - val_loss: 0.5249 - val_binary_accuracy: 0.7361\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 92s - loss: 0.5091 - binary_accuracy: 0.7462 - val_loss: 0.5238 - val_binary_accuracy: 0.7340\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.52209 to 0.51779, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-15-0.52.hdf5\n",
      " - 98s - loss: 0.5077 - binary_accuracy: 0.7435 - val_loss: 0.5178 - val_binary_accuracy: 0.7351\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 91s - loss: 0.5024 - binary_accuracy: 0.7477 - val_loss: 0.5279 - val_binary_accuracy: 0.7383\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.51779 to 0.51663, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-17-0.52.hdf5\n",
      " - 97s - loss: 0.5014 - binary_accuracy: 0.7457 - val_loss: 0.5166 - val_binary_accuracy: 0.7361\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 91s - loss: 0.5007 - binary_accuracy: 0.7463 - val_loss: 0.5209 - val_binary_accuracy: 0.7340\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.51663 to 0.51558, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-19-0.52.hdf5\n",
      " - 97s - loss: 0.4979 - binary_accuracy: 0.7466 - val_loss: 0.5156 - val_binary_accuracy: 0.7394\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.51558 to 0.51524, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-20-0.52.hdf5\n",
      " - 97s - loss: 0.4962 - binary_accuracy: 0.7478 - val_loss: 0.5152 - val_binary_accuracy: 0.7394\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 91s - loss: 0.4924 - binary_accuracy: 0.7523 - val_loss: 0.5180 - val_binary_accuracy: 0.7383\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 91s - loss: 0.4908 - binary_accuracy: 0.7510 - val_loss: 0.5169 - val_binary_accuracy: 0.7361\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 91s - loss: 0.4901 - binary_accuracy: 0.7518 - val_loss: 0.5154 - val_binary_accuracy: 0.7351\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.51524 to 0.51248, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-24-0.51.hdf5\n",
      " - 97s - loss: 0.4897 - binary_accuracy: 0.7538 - val_loss: 0.5125 - val_binary_accuracy: 0.7404\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.51248 to 0.51055, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-25-0.51.hdf5\n",
      " - 97s - loss: 0.4872 - binary_accuracy: 0.7533 - val_loss: 0.5105 - val_binary_accuracy: 0.7394\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 91s - loss: 0.4855 - binary_accuracy: 0.7545 - val_loss: 0.5120 - val_binary_accuracy: 0.7431\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 92s - loss: 0.4860 - binary_accuracy: 0.7525 - val_loss: 0.5133 - val_binary_accuracy: 0.7383\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.51055 to 0.50586, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/attentiondanq_weights\\weights-28-0.51.hdf5\n",
      " - 98s - loss: 0.4841 - binary_accuracy: 0.7553 - val_loss: 0.5059 - val_binary_accuracy: 0.7394\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 92s - loss: 0.4834 - binary_accuracy: 0.7568 - val_loss: 0.5167 - val_binary_accuracy: 0.7399\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 92s - loss: 0.4835 - binary_accuracy: 0.7573 - val_loss: 0.5108 - val_binary_accuracy: 0.7496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x280f94cd550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to DanQ as above\n",
    "# but with two conv filters in front\n",
    "\n",
    "# build our model\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x1 = Conv1D(128, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x2 = Conv1D(128, kernel_size=16, strides=1, padding='same', activation='relu')(x1)\n",
    "x = Concatenate()([x1, x2])\n",
    "x = MaxPooling1D(pool_size=8, strides=8)(x)\n",
    "x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualcnnconcat_danq_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68035, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-01-0.68.hdf5\n",
      " - 67s - loss: 0.6905 - binary_accuracy: 0.5375 - val_loss: 0.6803 - val_binary_accuracy: 0.5574\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68035 to 0.64723, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-02-0.65.hdf5\n",
      " - 65s - loss: 0.6693 - binary_accuracy: 0.5934 - val_loss: 0.6472 - val_binary_accuracy: 0.6581\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.64723 to 0.62268, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-03-0.62.hdf5\n",
      " - 65s - loss: 0.6337 - binary_accuracy: 0.6445 - val_loss: 0.6227 - val_binary_accuracy: 0.6559\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.62268 to 0.58831, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-04-0.59.hdf5\n",
      " - 65s - loss: 0.6041 - binary_accuracy: 0.6704 - val_loss: 0.5883 - val_binary_accuracy: 0.6887\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 60s - loss: 0.5848 - binary_accuracy: 0.6893 - val_loss: 0.6093 - val_binary_accuracy: 0.6597\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.58831 to 0.57075, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-06-0.57.hdf5\n",
      " - 65s - loss: 0.5758 - binary_accuracy: 0.6926 - val_loss: 0.5707 - val_binary_accuracy: 0.6957\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.57075 to 0.56055, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-07-0.56.hdf5\n",
      " - 65s - loss: 0.5701 - binary_accuracy: 0.6979 - val_loss: 0.5606 - val_binary_accuracy: 0.7081\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56055 to 0.55770, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-08-0.56.hdf5\n",
      " - 65s - loss: 0.5654 - binary_accuracy: 0.7037 - val_loss: 0.5577 - val_binary_accuracy: 0.7108\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 60s - loss: 0.5604 - binary_accuracy: 0.7068 - val_loss: 0.5580 - val_binary_accuracy: 0.7071\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.55770 to 0.55229, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-10-0.55.hdf5\n",
      " - 66s - loss: 0.5546 - binary_accuracy: 0.7106 - val_loss: 0.5523 - val_binary_accuracy: 0.7173\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 62s - loss: 0.5552 - binary_accuracy: 0.7116 - val_loss: 0.5533 - val_binary_accuracy: 0.7157\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.55229 to 0.55024, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-12-0.55.hdf5\n",
      " - 74s - loss: 0.5479 - binary_accuracy: 0.7168 - val_loss: 0.5502 - val_binary_accuracy: 0.7087\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.55024 to 0.54403, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-13-0.54.hdf5\n",
      " - 83s - loss: 0.5480 - binary_accuracy: 0.7154 - val_loss: 0.5440 - val_binary_accuracy: 0.7141\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 67s - loss: 0.5459 - binary_accuracy: 0.7162 - val_loss: 0.5443 - val_binary_accuracy: 0.7173\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.54403 to 0.53989, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-15-0.54.hdf5\n",
      " - 65s - loss: 0.5419 - binary_accuracy: 0.7209 - val_loss: 0.5399 - val_binary_accuracy: 0.7200\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.53989 to 0.53765, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-16-0.54.hdf5\n",
      " - 65s - loss: 0.5410 - binary_accuracy: 0.7194 - val_loss: 0.5377 - val_binary_accuracy: 0.7167\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 60s - loss: 0.5355 - binary_accuracy: 0.7235 - val_loss: 0.5404 - val_binary_accuracy: 0.7232\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.53765 to 0.53521, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-18-0.54.hdf5\n",
      " - 65s - loss: 0.5369 - binary_accuracy: 0.7229 - val_loss: 0.5352 - val_binary_accuracy: 0.7237\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.53521 to 0.53462, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-19-0.53.hdf5\n",
      " - 65s - loss: 0.5337 - binary_accuracy: 0.7272 - val_loss: 0.5346 - val_binary_accuracy: 0.7221\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.53462 to 0.53269, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-20-0.53.hdf5\n",
      " - 65s - loss: 0.5307 - binary_accuracy: 0.7286 - val_loss: 0.5327 - val_binary_accuracy: 0.7286\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.53269 to 0.52928, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-21-0.53.hdf5\n",
      " - 65s - loss: 0.5285 - binary_accuracy: 0.7280 - val_loss: 0.5293 - val_binary_accuracy: 0.7302\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 60s - loss: 0.5262 - binary_accuracy: 0.7338 - val_loss: 0.5301 - val_binary_accuracy: 0.7334\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 60s - loss: 0.5256 - binary_accuracy: 0.7323 - val_loss: 0.5376 - val_binary_accuracy: 0.7227\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 60s - loss: 0.5245 - binary_accuracy: 0.7323 - val_loss: 0.5353 - val_binary_accuracy: 0.7254\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 60s - loss: 0.5222 - binary_accuracy: 0.7324 - val_loss: 0.5323 - val_binary_accuracy: 0.7345\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.52928 to 0.52700, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-26-0.53.hdf5\n",
      " - 65s - loss: 0.5220 - binary_accuracy: 0.7333 - val_loss: 0.5270 - val_binary_accuracy: 0.7356\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 60s - loss: 0.5176 - binary_accuracy: 0.7359 - val_loss: 0.5345 - val_binary_accuracy: 0.7281\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.52700 to 0.52247, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-28-0.52.hdf5\n",
      " - 65s - loss: 0.5202 - binary_accuracy: 0.7334 - val_loss: 0.5225 - val_binary_accuracy: 0.7377\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 60s - loss: 0.5195 - binary_accuracy: 0.7360 - val_loss: 0.5269 - val_binary_accuracy: 0.7334\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 60s - loss: 0.5165 - binary_accuracy: 0.7363 - val_loss: 0.5235 - val_binary_accuracy: 0.7345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ca7c80ef0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dual 1Dconv-LSTM, second conv is depthwise-first\n",
    "# concat prior to LSTM\n",
    "\n",
    "# build our model\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x1 = Conv1D(256, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x2 = SeparableConv1D(256, kernel_size=16, strides=1, padding='same', activation='relu')(x1)\n",
    "x = Concatenate()([x1, x2])\n",
    "x = MaxPooling1D(pool_size=8, strides=8)(x)\n",
    "x = Bidirectional(CuDNNLSTM(256, return_sequences=True))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 672, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 672, 4)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 672, 128)     8320        gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 672, 128)     262272      conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 672, 256)     0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 672, 128)     524416      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 672, 384)     0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 84, 384)      0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 84, 256)      526336      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 21504)        0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         22021120    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,343,489\n",
      "Trainable params: 23,343,489\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67049, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-01-0.67.hdf5\n",
      " - 61s - loss: 0.6874 - binary_accuracy: 0.5435 - val_loss: 0.6705 - val_binary_accuracy: 0.5757\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67049 to 0.60837, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-02-0.61.hdf5\n",
      " - 58s - loss: 0.6464 - binary_accuracy: 0.6292 - val_loss: 0.6084 - val_binary_accuracy: 0.6656\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60837 to 0.58266, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-03-0.58.hdf5\n",
      " - 59s - loss: 0.6042 - binary_accuracy: 0.6710 - val_loss: 0.5827 - val_binary_accuracy: 0.6979\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58266 to 0.56297, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-04-0.56.hdf5\n",
      " - 59s - loss: 0.5820 - binary_accuracy: 0.6884 - val_loss: 0.5630 - val_binary_accuracy: 0.6914\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56297 to 0.56140, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-05-0.56.hdf5\n",
      " - 59s - loss: 0.5714 - binary_accuracy: 0.7010 - val_loss: 0.5614 - val_binary_accuracy: 0.6941\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56140 to 0.55098, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-06-0.55.hdf5\n",
      " - 59s - loss: 0.5633 - binary_accuracy: 0.7051 - val_loss: 0.5510 - val_binary_accuracy: 0.7119\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 57s - loss: 0.5576 - binary_accuracy: 0.7076 - val_loss: 0.5579 - val_binary_accuracy: 0.7049\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 57s - loss: 0.5492 - binary_accuracy: 0.7146 - val_loss: 0.5616 - val_binary_accuracy: 0.6887\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.55098 to 0.54215, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-09-0.54.hdf5\n",
      " - 60s - loss: 0.5447 - binary_accuracy: 0.7165 - val_loss: 0.5421 - val_binary_accuracy: 0.7194\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 57s - loss: 0.5423 - binary_accuracy: 0.7206 - val_loss: 0.5497 - val_binary_accuracy: 0.7130\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.54215 to 0.54085, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-11-0.54.hdf5\n",
      " - 60s - loss: 0.5383 - binary_accuracy: 0.7199 - val_loss: 0.5408 - val_binary_accuracy: 0.7264\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.54085 to 0.53725, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-12-0.54.hdf5\n",
      " - 59s - loss: 0.5357 - binary_accuracy: 0.7264 - val_loss: 0.5372 - val_binary_accuracy: 0.7270\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.53725 to 0.53270, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-13-0.53.hdf5\n",
      " - 59s - loss: 0.5299 - binary_accuracy: 0.7279 - val_loss: 0.5327 - val_binary_accuracy: 0.7243\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 57s - loss: 0.5258 - binary_accuracy: 0.7264 - val_loss: 0.5345 - val_binary_accuracy: 0.7270\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.53270 to 0.52524, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-15-0.53.hdf5\n",
      " - 60s - loss: 0.5237 - binary_accuracy: 0.7320 - val_loss: 0.5252 - val_binary_accuracy: 0.7367\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 57s - loss: 0.5221 - binary_accuracy: 0.7348 - val_loss: 0.5376 - val_binary_accuracy: 0.7124\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 57s - loss: 0.5189 - binary_accuracy: 0.7332 - val_loss: 0.5318 - val_binary_accuracy: 0.7211\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.52524 to 0.52458, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-18-0.52.hdf5\n",
      " - 59s - loss: 0.5164 - binary_accuracy: 0.7349 - val_loss: 0.5246 - val_binary_accuracy: 0.7254\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 57s - loss: 0.5144 - binary_accuracy: 0.7364 - val_loss: 0.5318 - val_binary_accuracy: 0.7302\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 57s - loss: 0.5147 - binary_accuracy: 0.7359 - val_loss: 0.5273 - val_binary_accuracy: 0.7270\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.52458 to 0.51944, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-21-0.52.hdf5\n",
      " - 59s - loss: 0.5107 - binary_accuracy: 0.7407 - val_loss: 0.5194 - val_binary_accuracy: 0.7324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 57s - loss: 0.5087 - binary_accuracy: 0.7392 - val_loss: 0.5218 - val_binary_accuracy: 0.7345\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 57s - loss: 0.5090 - binary_accuracy: 0.7416 - val_loss: 0.5289 - val_binary_accuracy: 0.7324\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 57s - loss: 0.5083 - binary_accuracy: 0.7347 - val_loss: 0.5228 - val_binary_accuracy: 0.7313\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 57s - loss: 0.5052 - binary_accuracy: 0.7433 - val_loss: 0.5200 - val_binary_accuracy: 0.7291\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 57s - loss: 0.5077 - binary_accuracy: 0.7423 - val_loss: 0.5249 - val_binary_accuracy: 0.7302\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 57s - loss: 0.5026 - binary_accuracy: 0.7428 - val_loss: 0.5245 - val_binary_accuracy: 0.7324\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.51944 to 0.51562, saving model to D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-28-0.52.hdf5\n",
      " - 59s - loss: 0.5033 - binary_accuracy: 0.7434 - val_loss: 0.5156 - val_binary_accuracy: 0.7313\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 57s - loss: 0.5028 - binary_accuracy: 0.7431 - val_loss: 0.5169 - val_binary_accuracy: 0.7307\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 57s - loss: 0.5005 - binary_accuracy: 0.7457 - val_loss: 0.5231 - val_binary_accuracy: 0.7329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x283ddebad68>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to DanQ as above\n",
    "# but with two conv filters in front\n",
    "\n",
    "# build our model\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x1 = Conv1D(128, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x2 = Conv1D(128, kernel_size=16, strides=1, padding='same', activation='relu')(x1)\n",
    "x3 = Concatenate()([x1, x2])\n",
    "x3 = Conv1D(128, kernel_size=16, strides=1, padding='same', activation='relu')(x3)\n",
    "x = Concatenate()([x1, x2, x3])\n",
    "x = MaxPooling1D(pool_size=8, strides=8)(x)\n",
    "x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# save path, callbacks\n",
    "save_path = 'D:/Projects/Github/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights'\n",
    "\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.5,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               epsilon=0.0001,\n",
    "                               cooldown=1,\n",
    "                               min_lr=1e-6)\n",
    "\n",
    "save_model = ModelCheckpoint(os.path.join(save_path, 'weights-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_path, 'training_history.csv'), separator=',', append=False)\n",
    "\n",
    "\n",
    "# train model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_test.npy')\n",
    "y_test = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_test.npy')\n",
    "\n",
    "model_list = ['D:/Projects/iSynpro/SyntheticPromoter/DanQCNNLSTM/danq_weights/weights-28-0.52.hdf5',\n",
    "              'D:/Projects/iSynpro/SyntheticPromoter/DanQCNNLSTM/smallkerneldanq_weights/weights-29-0.52.hdf5',\n",
    "              'D:/Projects/iSynpro/SyntheticPromoter/DanQCNNLSTM/smallstridedanq_weights/weights-30-0.51.hdf5',\n",
    "              'D:/Projects/iSynpro/SyntheticPromoter/DanQCNNLSTM/dualcnnconcat_danq_weights/weights-28-0.51.hdf5',\n",
    "              'D:/Projects/iSynpro/SyntheticPromoter/DanQCNNLSTM/triplecnnconcat_danq_weights\\weights-28-0.52.hdf5',\n",
    "              'D:/Projects/iSynpro/SyntheticPromoter/DanQCNNLSTM/dualseparable_cnnlstm_weights\\weights-28-0.52.hdf5'\n",
    "             ]\n",
    "label_list = ['DanQ', 'Small Kernel', 'Small Stride', 'Dual Conv Stem', 'Triple Conv Stem', 'Dual Separable Conv Stem']\n",
    "roc_list = []\n",
    "for path in model_list:\n",
    "    model = load_model(path)\n",
    "    y_pred = model.predict(x_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_list.append([fpr, tpr, auc])\n",
    "    K.clear_session()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKppT0NDQ0NBQ+X8/aKp7c6VNhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d758a55a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "palette = sns.color_palette(\"cubehelix\", len(roc_list))\n",
    "\n",
    "#plot roc curve\n",
    "for i in range(len(roc_list)):\n",
    "    plt.plot(roc_list[i][0], \n",
    "             roc_list[i][1], \n",
    "             color=palette[i], \n",
    "             label='{0} (AUC = {1:.3f})'.format(label_list[i], roc_list[i][2]))\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Vanilla CNN-LSTMs')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('d:/projects/isynpro/SyntheticPromoter/readme_figures/cnnlstm_roc.png', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
