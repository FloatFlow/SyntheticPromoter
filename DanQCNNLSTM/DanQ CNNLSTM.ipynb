{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, AveragePooling2D, Dense, Dropout, Activation, AveragePooling1D, Bidirectional, MaxPooling2D, GaussianNoise\n",
    "from keras.layers import Input, Concatenate, Flatten, Embedding, CuDNNLSTM, Conv1D, MaxPooling1D, LSTM, StackedRNNCells, LSTMCell, Reshape, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, SGD, adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-5ba25a88fc81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_target_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNoise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m#x = MaxPooling1D(pool_size=8, strides=2)(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCuDNNLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_uid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# (num_samples * timesteps, ...)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_uses_learning_phase'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0muses_learning_phase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    158\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                 dilation_rate=self.dilation_rate[0])\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             outputs = K.conv2d(\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mconv1d\u001b[1;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m   3292\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3293\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3294\u001b[1;33m         data_format=tf_data_format)\n\u001b[0m\u001b[0;32m   3295\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[1;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[0;32m    748\u001b[0m                      \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m                      \u001b[0mdilation_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m                      name=name, data_format=data_format)\n\u001b[0m\u001b[0;32m    751\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NC\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m       \u001b[0minput_channels_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_spatial_dims\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m       \u001b[0mspatial_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_spatial_dims\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Basic 1D Conv CNN LSTM with timedistributed conv\n",
    "\n",
    "start_target_size = (672, 4)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_train.npy')\n",
    "\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x = Conv1D(64, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "#x = MaxPooling1D(pool_size=8, strides=2)(x)\n",
    "x = Bidirectional(CuDNNLSTM(512, return_sequences=True))(x)\n",
    "#x = Flatten()(x)\n",
    "x = TimeDistributed(Dense(32, activation='relu'))(x)\n",
    "#x = MaxPooling1D(pool_size=8, strides=2)(x)\n",
    "#x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x) #works if return_sequences=True\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, output = predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=0.001, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "# Basic 1D Conv CNN LSTM\n",
    "\n",
    "start_target_size = (672, 4)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_train.npy')\n",
    "\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x = Conv1D(256, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "#x = MaxPooling1D(pool_size=8, strides=2)(x)\n",
    "x = Bidirectional(CuDNNLSTM(512, return_sequences=True))(x)\n",
    "#x = Flatten()(x)\n",
    "x = TimeDistributed(Dense(32, activation='relu'))(x)\n",
    "#x = MaxPooling1D(pool_size=8, strides=2)(x)\n",
    "#x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x) #works if return_sequences=True\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, output = predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=0.001, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 672, 4)            0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo (None, 672, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 672, 256)          16640     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 672, 1024)         3153920   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 672, 32)           32800     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 333, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10656)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10656)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              10912768  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,641,441\n",
      "Trainable params: 14,641,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "# Basic 1D Conv CNN LSTM\n",
    "# it actually works!\n",
    "\n",
    "start_target_size = (672, 4)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_train.npy')\n",
    "\n",
    "inputs = Input(shape=start_target_size)\n",
    "x = GaussianNoise(0.3)(inputs)\n",
    "x = Conv1D(256, kernel_size=16, strides=1, padding='same', activation='relu')(x)\n",
    "x = MaxPooling1D(pool_size=8, strides=8)(x)\n",
    "x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, output = predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= SGD(lr=0.001, momentum=0.9),\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_target_size = (672, 4)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_train.npy')\n",
    "\n",
    "inputs = Input(shape = start_target_size[:])\n",
    "x = Reshape((672, 4, 1))(inputs)\n",
    "# conv block 1\n",
    "x = Conv2D(512, kernel_size=(30, 4), strides=(1, 1), padding='same')(x)\n",
    "#x = Reshape((672, 1, 256))(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(15, 4), strides=(15,1))(x) #sparse maxpool, half of kernel_size, seems to work the best so far\n",
    "x = Reshape((672//15, 512))(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "\n",
    "#cells = [LSTMCell(512), LSTMCell(512)]\n",
    "#x = StackedRNNCells(cells)(x) #originally bidirectional LSTM, not stacked cells\n",
    "\n",
    "\n",
    "x = Bidirectional(CuDNNLSTM(512, return_sequences=False), merge_mode = 'concat')(x)\n",
    "#x = CuDNNLSTM(512, return_sequences=False)(x)\n",
    "#x = TimeDistributed(Dense(8))(x)\n",
    "#x = Dropout(0.5)(x) \n",
    "#x = Flatten()(x)\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triple uni-directional LSTM after single Conv\n",
    "\n",
    "start_target_size = (672, 4)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_train.npy')\n",
    "\n",
    "inputs = Input(shape = start_target_size[:])\n",
    "xi = Reshape((672, 4, 1))(inputs)\n",
    "\n",
    "# tower 1\n",
    "x1 = Conv2D(256, kernel_size=(32, 4), strides=(1, 1), padding='same')(xi)\n",
    "x1 = Activation('relu')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(16, 4), strides=(16,1))(x1) #sparse maxpool seems to work the best so far\n",
    "x1 = Reshape((672//16, 256))(x1)\n",
    "#x1 = Bidirectional(CuDNNLSTM(512, return_sequences=False), merge_mode = 'concat')(x1)\n",
    "x1 = CuDNNLSTM(128, return_sequences=True)(x1)\n",
    "x1 = CuDNNLSTM(128, return_sequences=True)(x1)\n",
    "x1 = CuDNNLSTM(128, return_sequences=False)(x1)\n",
    "\n",
    "\n",
    "# exit stem\n",
    "x = Dense(1024, activation='relu')(x1)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "# compile model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double conv before LSTM\n",
    "# doesn't really work\n",
    "start_target_size = (672, 4)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_train.npy')\n",
    "\n",
    "inputs = Input(shape = start_target_size[:])\n",
    "xi = Reshape((672, 4, 1))(inputs)\n",
    "\n",
    "# tower 1\n",
    "x1 = Conv2D(256, kernel_size=(16, 4), strides=(1, 1), padding='same')(xi)\n",
    "x1 = Activation('relu')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "\n",
    "x1 = Conv2D(256, kernel_size=(16, 4), strides=(1, 1), padding='same')(x1)\n",
    "x1 = Activation('relu')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "\n",
    "x1 = MaxPooling2D(pool_size=(4, 4), strides=(4,1))(x1) #sparse maxpool seems to work the best so far\n",
    "x1 = Reshape((672//4, 256))(x1)\n",
    "x1 = Bidirectional(CuDNNLSTM(512, return_sequences=False), merge_mode = 'concat')(x1)\n",
    "\n",
    "x = Dense(1024, activation='relu')(x1)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "# compile model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Tries to capture motifs of different sizes, feeds to individual bidirectional LSTMs,\n",
    "# then merges to FC layer\n",
    "#\n",
    "\n",
    "start_target_size = (672, 4)\n",
    "batch_size = 16\n",
    "x_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/x_train.npy')\n",
    "y_train = np.load('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/y_train.npy')\n",
    "\n",
    "inputs = Input(shape = start_target_size[:])\n",
    "xi = Reshape((672, 4, 1))(inputs)\n",
    "\n",
    "# tower 1\n",
    "x1 = Conv2D(64, kernel_size=(32, 4), strides=(1, 1), padding='same')(xi)\n",
    "x1 = Activation('relu')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(16, 4), strides=(16,1))(x1) #sparse maxpool seems to work the best so far\n",
    "x1 = Reshape((672//16, 64))(x1)\n",
    "x1 = Bidirectional(CuDNNLSTM(512, return_sequences=True), merge_mode = 'concat')(x1)\n",
    "#x1 = Flatten()(x1)\n",
    "\n",
    "# tower 2\n",
    "x2 = Conv2D(128, kernel_size=(16, 4), strides=(1, 1), padding='same')(xi)\n",
    "x2 = Activation('relu')(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(8, 4), strides=(8,1))(x2) #sparse maxpool seems to work the best so far\n",
    "x2 = Reshape((672//8, 128))(x2)\n",
    "x2 = Bidirectional(CuDNNLSTM(512, return_sequences=True), merge_mode = 'concat')(x2)\n",
    "#x2 = Flatten()(x2)\n",
    "\n",
    "# tower 3\n",
    "x3 = Conv2D(64, kernel_size=(8, 4), strides=(1, 1), padding='same')(xi)\n",
    "x3 = Activation('relu')(x3)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = MaxPooling2D(pool_size=(4, 4), strides=(4,1))(x3) #sparse maxpool seems to work the best so far\n",
    "x3 = Reshape((672//4, 64))(x3)\n",
    "x3 = Bidirectional(CuDNNLSTM(512, return_sequences=True), merge_mode = 'concat')(x3)\n",
    "#x3 = Flatten()(x3)\n",
    "\n",
    "\n",
    "# exit stem\n",
    "x = Concatenate()([x1, x2, x3])\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "# compile model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.03, momentum=0.9), metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 672, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 672, 4, 1)    0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 672, 4, 64)   8256        reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 672, 4, 128)  8320        reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 672, 4, 64)   2112        reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 672, 4, 64)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 672, 4, 128)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 672, 4, 64)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 672, 4, 64)   256         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 672, 4, 128)  512         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 672, 4, 64)   256         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 42, 1, 64)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 84, 1, 128)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 168, 1, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 42, 64)       0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 84, 128)      0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 168, 64)      0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1024)         2367488     reshape_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1024)         2629632     reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1024)         2367488     reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3072)         0           bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1024)         3146752     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1024)         1049600     dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            1025        dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 11,581,697\n",
      "Trainable params: 11,581,185\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16708 samples, validate on 1857 samples\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67875, saving model to D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/weights/weights-01-0.68.hdf5\n",
      " - 297s - loss: 0.6888 - binary_accuracy: 0.5496 - val_loss: 0.6787 - val_binary_accuracy: 0.5708\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67875 to 0.61604, saving model to D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/weights/weights-02-0.62.hdf5\n",
      " - 300s - loss: 0.6541 - binary_accuracy: 0.6165 - val_loss: 0.6160 - val_binary_accuracy: 0.6473\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.61604 to 0.58108, saving model to D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/weights/weights-03-0.58.hdf5\n",
      " - 298s - loss: 0.6066 - binary_accuracy: 0.6594 - val_loss: 0.5811 - val_binary_accuracy: 0.6990\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.58108 to 0.56724, saving model to D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/weights/weights-04-0.57.hdf5\n",
      " - 299s - loss: 0.5859 - binary_accuracy: 0.6865 - val_loss: 0.5672 - val_binary_accuracy: 0.7065\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56724 to 0.56659, saving model to D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/weights/weights-05-0.57.hdf5\n",
      " - 298s - loss: 0.5736 - binary_accuracy: 0.6953 - val_loss: 0.5666 - val_binary_accuracy: 0.7065\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56659 to 0.55910, saving model to D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/weights/weights-06-0.56.hdf5\n",
      " - 297s - loss: 0.5675 - binary_accuracy: 0.6979 - val_loss: 0.5591 - val_binary_accuracy: 0.7060\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.55910 to 0.55509, saving model to D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/weights/weights-07-0.56.hdf5\n",
      " - 299s - loss: 0.5610 - binary_accuracy: 0.7031 - val_loss: 0.5551 - val_binary_accuracy: 0.7119\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 298s - loss: 0.5550 - binary_accuracy: 0.7101 - val_loss: 0.5588 - val_binary_accuracy: 0.6941\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.55509 to 0.55507, saving model to D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/weights/weights-09-0.56.hdf5\n",
      " - 299s - loss: 0.5485 - binary_accuracy: 0.7146 - val_loss: 0.5551 - val_binary_accuracy: 0.7087\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.55507 to 0.54779, saving model to D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/weights/weights-10-0.55.hdf5\n",
      " - 297s - loss: 0.5447 - binary_accuracy: 0.7194 - val_loss: 0.5478 - val_binary_accuracy: 0.7119\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-e58b275be698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m           callbacks = [save_model, csv_logger])\n\u001b[0m",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wolfgang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_decay = 0.96 #not used\n",
    "\n",
    "\n",
    "#our callbacks\n",
    "lr_descent = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.5,\n",
    "                                               patience=5,\n",
    "                                               verbose=1,\n",
    "                                               mode='auto',\n",
    "                                               epsilon=0.0001,\n",
    "                                               cooldown=1,\n",
    "                                               min_lr=0)\n",
    "\n",
    "save_model = ModelCheckpoint('D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/weights/weights-{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                                             monitor='val_loss',\n",
    "                                             verbose=1, \n",
    "                                             save_best_only=True,\n",
    "                                             save_weights_only=False,\n",
    "                                             mode='auto',\n",
    "                                             period=1)\n",
    "\n",
    "csv_path = 'D:/Projects/iSynPro/iSynPro/DanQCNNLSTM/weights/training_history.csv'\n",
    "csv_logger = CSVLogger(csv_path, separator=',', append=False)\n",
    "\n",
    "def incep_resnet_schedule(epoch):\n",
    "    if epoch % 2 == 0:\n",
    "        return 0.045*(0.96**(epoch))\n",
    "    else:\n",
    "        return 0.045*(0.96**((epoch)-1.0))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(incep_resnet_schedule)\n",
    "\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=16, \n",
    "          epochs=30,\n",
    "          shuffle=True,\n",
    "          verbose=2, \n",
    "          validation_split=0.1,\n",
    "          callbacks = [save_model, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
